\documentclass{article}
%% \usepackage{fullpage}
\usepackage{latexsym}
\usepackage{naaclhlt2013}
\usepackage{url}
% \pagenumbering{gobble}

\title{Cross-lingual Word Sense Disambiguation for Low-Resource Hybrid Machine
Translation}
\author{Alex Rudnick \\
	    Indiana University, School of Informatics and Computing \\
	    {\tt alexr@indiana.edu}}
\date{}

\begin{document}
\maketitle

\section{Overview}
Here I describe work, both underway and planned, on cross-lingual word sense
disambiguation (CL-WSD) and its practical application to a hybrid
rule-based/statistical machine translation system for the Spanish-Guarani
language pair, the co-official languages of Paraguay. So far, we have used
evidence from multilingual sources and sequence-labeling approaches to address
lexical ambiguity in translation. In future work, I plan to collect more useful
bilingual data for our chosen language pair through crowdsourcing, and to
integrate the disambiguation system into our rule-based translation engine,
producing a hybrid rule-based/statistical translation system.

Lexical ambiguity presents a serious challenge for rule-based machine
translation (RBMT) systems, since many words have several possible translations
in a given target language. Moreover, several translations of a given word may
be syntactically valid in context, and the alternatives may have significantly
different meanings. Even when choosing among near-synonyms, we would like to
respect the selectional preferences of the target language so as to produce
natural-sounding output text.

Writing lexical selection rules by hand is tedious and error-prone; even if
informants familiar with both languages are available, they may not be able to
enumerate the contexts under which they would choose one alternative over
another. Thus we would like to learn from corpora when possible. However, for
most language pairs, large sentence-aligned bitext corpora are not available,
so part of the work of creating and deploying a practical machine translation
system trained on corpus data will involve collecting a larger corpus.

We want to show that cross-lingual word sense disambiguation techniques are a
feasible and practical means for lexical selection in a low-resource machine
translation setting, and to demonstrate this in practice by translating from
Spanish to Guarani. The major contributions of this work will be: (a) new
approaches for CL-WSD and its integration into an RBMT system; (b) a website
where language learners and activists can help build large bilingual corpora;
(c) a suite of reusable open-source software; and (d) to our knowledge, the
first deployed MT system for the Spanish-Guarani language pair.

\section{Using multilingual evidence}
We have been investigating how to use multiple bitext corpora for a CL-WSD
task, allowing us to leverage bitext corpora for language pairs other than the
one for which we are currently doing translation.

This was largely informed by the work of Lefever and Hoste
\cite{lefever-hoste-decock:2011:ACL-HLT2011}, although their approach requires
an entire machine translation system to perform CL-WSD -- whereas we consider
CL-WSD to be a subproblem of MT. Thus we would like to perform CL-WSD without
depending on a complete machine translation system.

Earlier this year, we developed three CL-WSD systems for a SemEval shared task
\cite{rudnick-liu-gasser:2013:SemEval-2013}, showing how to do exactly this,
using classifier stacking and graphical models. This work, as per the shared
task \cite{task10}, did translation from English to other European languages,
and we have yet to adapt it translating into Guarani.

\section{Lexical selection as a sequence labeling problem}
In \cite{rudnick-gasser:2013:HyTra-2013} ...

We have recently started investigating the use of sequence-labeling models for
lexical selection. The intuition here is that machine translation implies an
``all-words" WSD task, in that we need to choose a translation for every word
or phrase in the source sentence, and that the sequence of translations should
make sense when taken together.

So far, we have used a combination of Hidden Markov Models and Maximum Entropy
Markov Models to do lexical selection in a both English-Spanish and
Spanish-Guarani translation tasks. This will need to be investigated further,
especially as we vary the amounts of available training data and the feature
sets available to the classifiers. More sophisticated sequence models, such as
Conditional Random Fields, may be useful in this task as well.

\section{Integrating CL-WSD in Rule-Based Machine Translation}
We are currently working with L3, a rule-based machine translation system based
on constraint solving and synchronous dependency grammars, developed by Michael
Gasser \cite{gasser:sxdg} \cite{gasser:aflat2012}.

However, it currently needs a good way to make decisions about the best way to
translate 

\section{Acquiring and using larger bitext corpora}
We want to apply these techniques to the concrete problem of translating from
Spanish to Guarani, an indigenous language of South America. Guarani is
disadvantaged in a socio-economic sense, but is broadly spoken in Paraguay. The
majority of Paraguayans speak Guarani, and are likely to be bilingual with
Spanish. In practice, many use a combination of the two called Jopar{\'a}.

The goal for hybrid rule-based and statistical translation systems, such as L3,
is to make use of the available linguistic knowledge about the source and
target language, in the form of translation rules, but also to make use of any
available training text, either monolingual or bilingual, improving with the
increased corpora size.

Thus we are developing a TAHEKAMI, a platform for helping language teachers and
activists translate text into their preferred language...

%% Framing the resolution of lexical ambiguities in machine translation as an
%% explicit classification task has a long history; practical work in integrating
%% WSD with statistical machine translation dates back to early SMT work at IBM
%% \cite{Brown91word-sensedisambiguation}, but the problem itself was described in
%% Warren Weaver's prescient 1949 memorandum \cite{warrenmemo}, the fifth section
%% of which outlines the modern conception of word sense diambiguation.
%% More recently, Carpuat and Wu have shown how to use word-sense disambiguation
%% techniques to improve modern phrase-based SMT systems \cite{carpuatpsd}, even
%% though most SMT systems do not use an explicit WSD module \cite{wsdchap3}, as
%% the language model and phrase tables of these systems mitigate lexical
%% ambiguities somewhat.
%% 
%% Treating lexical selection as a word-sense disambiguation problem in
%% which the sense inventory for each source-language word is its set of possible
%% translations is often called cross-lingual WSD (CL-WSD). This framing has
%% received enough attention to warrant shared tasks at recent SemEval workshops;
%% the most recent running of the task is described in \cite{task10}.

\bibliographystyle{naaclhlt2013.bst}
\bibliography{prospectus.bib}{}

\end{document}
