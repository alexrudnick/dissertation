\chapter{Summary and Future Work}
\label{chap:conclusions}

In this work, we have described some approaches and running software for
cross-lingual word sense disambiguation, particularly in the setting where we
are translating from a resource-rich language into an under-resourced one.
We have shown how these techniques can be applicable for translation targeting
two different indigenous languages of South America, Guarani and Quechua.

We have extended our initial approach with the use of a number of techniques
that make use of the resources, both textual and software, available for our
source language.
including bitext corpora that pair our source language with languages other
than our intended target language.
Finally, we have demonstrated prototypes for how to integrate these CL-WSD
classifiers into existing machine translation software.

%% XXX working here

\section{Applying techniques like this to neural machine translation}
Since the start of this work, the field of machine translation has undergone a
dramatic shift, in which MT research, and in many cases, practice, has moved
from phrase-based and tree-based SMT systems to models based on neural
networks.
%% XXX cite the GNMT paper!!

It would be reasonable to consider NMT systems to be performing CL-WSD, in the
sense that they have a representation of the whole input sentence available
while they are making output decisions. This vector representation has is
similar to the the doc2vec representations discussed in Chapter
\ref{chap:monolingual}, but learned specifically for the translation task. This
sentence-encoding process automates much of the feature engineering work that
would go into building a CL-WSD system. Thus it may not be useful to add
explicit CL-WSD classifiers to a neural MT system, although this is an
empirical question.

However, many of the difficulties addressed in this work still apply in the
Neural Machine Translation (NMT) setting. We are left with the issue of how to
learn from the available corpora and tools that we have on hand when
translating out of a resource-rich language, when we have little available
bitext. Can source-language parsers be integrated with NMT? Will this help when
translating into under-resourced languages?
How about other existing NLP tools, such as monolingual WSD?

In this work, we did not find it overwhelmingly helpful to use neural
embeddings based on relatively large corpora, at least not in a CL-WSD setting.
But can these monolingual source-language resources be used for NMT?
%% XXX find some references about this probably

There are a number of open questions in neural machine translation; there do
not seem to be widely-accepted approaches for leveraging existing resources to
improve translation into under-resourced languages. ... %% XXX working here

%% Maybe mention the multilingual NLP paper here?
There has already been significant work on multilingual neural machine
translation; ...



\section{Building resources for Guarani and other under-represented languages}
\label{sec:crowdsourcing}

While we have explored some techniques in this work that allow us to lean
somewhat on the resources that we have available for resource-rich source
languages, a clear way to improve translation for currently under-resourced
languages is to make them less under-resourced. Languages like Guarani and
Quechua have a comparable number of speakers as some relatively resource-rich
European languages, as well as engaged activist communities. For example,
Icelandic has fewer than a million speakers... XXX maybe pick a different
example
What about Danish? How many Danish speakers?

There have been fairly successful campaigns by technologists to work with
speakers of these languages to build resources for them.
%% XXX sentence needs work
For example, Mozilla Paraguay managed to localize the Firefox web browser for
Guarani, with the help of Guarani-speaking volunteers. Localizing an
application as complex as a web browser is an enormous task, requiring the
translation of XXX sentence-length messages; also notably, this task requires
choosing appropriate Guarani-language terms for technical concepts.
%% XXX needs citation, also when did this happen?

As a success story directly pertinent to machine translation, in 2013, Google
ran a crowdsourcing campaign in New Zealand that managed to collect
enough training data to build a phrase-based SMT system for the Māori
language\footnote{Post on the Google New Zealand blog:
\url{https://newzealand.googleblog.com/2013/12/kua-puta-google-whakamaori-ki-te-reo.html}}

%% XXX this needs to be reworked for sure

As part of the ongoing work for the practical goal of building a useful
Spanish-Guarani MT system, we would like to build larger training corpora,
containing both bitext and monolingual Guarani text.
To help in the collection, we plan to build two websites:
a collaborative online space for building translations of documents, 
and a searchable repository of Guarani and bilingual documents.
Initial designs for both of these sites were done as a master's project in HCI
by Alberto Samaniego\footnote{\url{http://albsama.com}}, who will hopefully
continue collaborating on this project from his native Paraguay.

The first website we will develop is called ``Tahekami", which means
\emph{let's search together} in Guarani.
Tahekami is a repository of Guarani and bilingual documents that will allow
searching, browsing documents by tag, and uploading new documents.

An initial version of this site is already well underway
\footnote{\url{http://github.com/hltdi/gn-documents}}.  We have a working
search engine based on the Whoosh library
\footnote{\url{http://bitbucket.org/mchaput/whoosh/wiki/Home}} and some sample
documents -- twelve masters theses from the \emph{Ateneo}. We will need to
develop policies for which documents are permissible for distribution through
this site and work on integrating morphological analysis into the search
engine. Currently, new documents must be approved by an administrator before
being added to the index.

The second website, tentatively called ``Guampa"
\footnote{A ``guampa", in Paraguay, is the cup from which one drinks yerba mate
or tereré. The term ``guampa" is also local to Paraguay; in other parts of
South America, the container itself is called a ``mate".},
will be used by Guarani speakers and learners to produce translations of
relevant documents from Spanish to Guarani or vice-versa.
It will be something like a bilingual wiki, although the interface will
encourage users to edit sentences individually.
The software will segment the sentences in the initial
source-language documents and allow users to contribute translations for each
source sentence in turn, while showing the complete document context.
As a result of this, not only will will we be able to collect bitext training
data, but we will also produce useful translations.

We presented an initial version of this software at LREC
2014\cite{RUDNICK14.151}.

Initially, this site will be seeded with documents from the Spanish and Guarani
Wikipedias. Successful translations of the Spanish-language articles could be
fed back into the Guarani Wikipedia. Other documents will be added by
Guarani-language educators and perhaps also pulled from Tahekami. Translations
may be assigned as homework by Guarani-language teachers.

The website will keep track of translations contributed by individual users;
there may be game-like features and community voting, where large number of
translations, or particularly good ones, are recognized, perhaps with virtual
prizes and badges.
Ideally, community management will be addressed by Paraguayan volunteers and
the gamification features can be built by contributors from the open source
world; this website and its richer features are not the primary focus of this
dissertation.

We may eventually collect enough bitext with this website such that it makes
sense to develop approaches for determining which sentences are the most
reliable and the most useful for training; this may correlate with quality
judgements from the human volunteers.
Investigating this relationship would make a good research question.

In the medium-term, this website will get an integrated ability to search
a translation memory and automatic suggestions from a machine translation
system\footnote{Features described in a presentation in Spanish here:
\url{http://www.cs.indiana.edu/~gasser/Taller2013/} ; English-language similar
presentation: \url{http://tinyurl.com/alexr-clingding-guarani} }
. While these features will be both useful and present a number of
interesting research questions, they are outside the scope of this
dissertation.
