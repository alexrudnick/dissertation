\chapter{Summary and Future Work}
\label{chap:conclusions}

In this work, we have described some approaches and running software for
cross-lingual word sense disambiguation, particularly in the setting where we
are translating from a resource-rich language into an under-resourced one.

We have shown how these techniques can be applicable for translation targeting
two different indigenous languages of South America, Guarani and Quechua. We
demonstrated, in Chapter \ref{chap:baseline}, an initial version of the system
based on common text classification features, and showed how it outperforms the
relatively strong most-frequent sense baseline.

We then extended that initial approach, in Chapter \ref{chap:monolingual} with
techniques that make use of the resources that we have available for Spanish,
including NLP tools for analyzing Spanish text, and unsupervised tools that
allow us to learn representations for our classifiers from the wealth of
available unannotated Spanish text, including Brown clusters and neural
embeddings.

In Chapter \ref{chap:multilingual}, we show how to ...
including bitext corpora that pair our source language with languages other
than our intended target language.

Finally, in Chapter \ref{chap:integration}, we have demonstrated prototypes for
integrating these CL-WSD classifiers into existing machine translation
software, demonstrating a phrase-based SMT system for
Spanish-Guarani\footnote{Ignoring, for the moment, the admittedly substantial
problem of morphological generation.} 

%% XXX working here

\section{Applying techniques like this to neural machine translation}
Since the start of this work, the field of machine translation has undergone a
dramatic shift, in which MT research, and in many cases, practice\cite{gnmt},
has moved from phrase-based and tree-based SMT systems to models based on
neural networks.

It would be reasonable to consider NMT systems to be performing CL-WSD, in the
sense that they have a representation of the whole input sentence available
while they are making output decisions. This vector representation has is
similar to the the doc2vec representations discussed in Chapter
\ref{chap:monolingual}, but learned specifically for the translation task. This
sentence-encoding process automates much of the feature engineering work that
would go into building a CL-WSD system. Thus it may not be useful to add
explicit CL-WSD classifiers to a neural MT system, although this is an
empirical question.

However, many of the difficulties addressed in this work still apply in the
Neural Machine Translation (NMT) setting. We are left with the issue of how to
learn from the available corpora and tools that we have on hand when
translating out of a resource-rich language, when we have little available
bitext. Can source-language parsers be integrated with NMT? Will this help when
translating into under-resourced languages?
How about other existing NLP tools, such as monolingual WSD?

In this work, we did not find it overwhelmingly helpful to use neural
embeddings based on relatively large corpora, at least not in a CL-WSD setting.
But can these monolingual source-language resources be used for NMT?
%% XXX find some references about this probably

There are a number of open questions in neural machine translation; there do
not seem to be widely-accepted approaches for leveraging existing resources to
improve translation into under-resourced languages. ... %% XXX working here

%% Maybe mention the multilingual NLP paper here?
There has already been significant work on multilingual neural machine
translation; ...
\cite{TACL1081}



\section{Building resources for Guarani and other under-represented languages}
\label{sec:crowdsourcing}

While we have explored techniques in this work that allow us to lean
somewhat on the resources that we have available for resource-rich source
languages, a clear way to improve translation for currently under-resourced
languages is to make them less under-resourced. Languages like Guarani and
Quechua have a comparable number of speakers as some relatively resource-rich
European languages, as well as engaged activist communities. For example,
Icelandic has fewer than a million speakers... XXX maybe pick a different
example
What about Danish? How many Danish speakers?
While this work has focused on languages spoken in South America, there are
languages around the world with similar situations: millions or possibly many
millions of speakers, but relatively little text on the web (thus far), and no
easily available MT or other good NLP tools.

%% XXX working here
These languages are not yet broadly used in publications on the web,
Internet usage is spreading quickly throughout the world, and
the speakers of these languages are coming online, and . There are many languages in
the world with similar 

There have been fairly successful campaigns by technologists to work with
speakers of these languages to build resources for them.
%% XXX sentence needs work
For example, Mozilla Paraguay managed to localize the Firefox web browser for
Guarani, with the help of Guarani-speaking volunteers. Localizing an
application as complex as a web browser is an enormous task, requiring the
translation of XXX sentence-length messages; also notably, this task requires
choosing appropriate Guarani-language terms for technical concepts.
%% XXX needs citation, also when did this happen?

As a success story directly pertinent to machine translation, in 2013, Google
ran a crowdsourcing campaign in New Zealand that managed to collect
enough training data to build a phrase-based SMT system for the Māori
language\footnote{Post on the Google New Zealand blog:
\url{https://newzealand.googleblog.com/2013/12/kua-puta-google-whakamaori-ki-te-reo.html}}

%% XXX this needs to be reworked for sure


We started some efforts along these lines, but a more sustained effort is
needed. We (the author, working together with Alberto Samaniego and Taylor
Skidmore, directed by Michael Gasser) prototyped two websites for collecting
Guarani and Spanish-Guarani language resources, but these have not been used
beyond the prototype stage.
The first website was called ``Tahekami", which means \emph{let's search
together} in Guarani. Tahekami\footnote{Prototype code at
\url{http://github.com/hltdi/gn-documents}} is a repository of Guarani and
bilingual documents that allows full-text search and browsing documents by tag.
Our initial version of the site contained a collection of masters theses from
the \emph{Ateneo de Lengua y Cultura Guaraní}.
We developed a second website, called ``Guampa" \footnote{A ``guampa", in
Paraguay, is the cup from which one drinks yerba mate or tereré. The term
``guampa" is also local to Paraguay; in other parts of South America, the
container itself is called a ``mate". The Guampa software is available at
\url{https://github.com/hltdi/guampa}}, is a bilingual wiki, which was designed
to be used by Guarani speakers and learners to collaboratively translate
documents from Spanish to Guarani or vice-versa. We presented an initial version
of this software at LREC 2014\cite{RUDNICK14.151}. This is meant to serve at
least three purposes: helping Guarani-language learners practice and get
feedback on their translations, creating more Guarani-language documents for the
web (we started initially with translating Spanish Wikipedia), and building
bitext corpora for training MT systems.

Michael Gasser is developing successors to these websites, in the form of
\emph{mitmita} and \emph{mainumby}, online computer-aided translation systems

In the medium-term, this website will get an integrated ability to search
a translation memory and automatic suggestions from a machine translation
system\footnote{Features described in a presentation in Spanish here:
\url{http://www.cs.indiana.edu/~gasser/Taller2013/} ; English-language similar
presentation: \url{http://tinyurl.com/alexr-clingding-guarani} }
. While these features will be both useful and present a number of
interesting research questions, they are outside the scope of this
dissertation.
