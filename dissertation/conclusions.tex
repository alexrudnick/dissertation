\chapter{Summary and Future Work}
\label{chap:conclusions}

In this work, we have described some approaches and running software for
cross-lingual word sense disambiguation, particularly in the setting where we
are translating from a resource-rich language into an under-resourced one.  We
have shown how cross-lingual word sense disambiguation can be applied to
lexical selection in a hybrid machine translation for language pairs with
relatively modest resources, particularly, when translating from Spanish to two
different indigenous languages of South America, Guarani and Quechua.

We described, in Chapter \ref{chap:baseline}, an initial version of the Chipa
software based on common text classification features, and showed how it
outperforms the relatively strong most-frequent sense baseline. We also
compared Chipa to other systems submitted to recent SemEval events for
cross-lingual word sense disambiguation, when translating from English to other
European languages.

In Chapter \ref{chap:monolingual}, we extended our initial approach with
strategies that make use of the available resources for Spanish, including NLP
tools for analyzing Spanish text and unsupervised learning techniques that
allow us to learn representations for our classifiers from the wealth of
available unannotated Spanish text, including Brown clusters and neural
embeddings that represent both individual word types and sequences of text.

In Chapter \ref{chap:multilingual}, we showed how to use Chipa for classifier
stacking, which allows us to learn from bitext corpora that pair our source
language with languages other than our intended target language; this technique
is broadly applicable when we want to translate out of a language with many
available bitext resources, and could also be applied when we have a good
monolingual WSD system available.

Finally, in Chapter \ref{chap:integration}, we demonstrated prototypes for
integrating our CL-WSD classifiers into existing machine translation systems of
two completely different architectures, requiring only small changes to
existing code.  We demonstrated a phrase-based SMT system for
Spanish-Guarani\footnote{Ignoring, for the moment, the admittedly substantial
problem of morphological generation.} that uses Chipa classifiers in a feature
function that guides its decoding process. For Spanish-Quechua, we augmented a
primarily rule-based hybrid machine translation system, using our classifiers
to supplement the existing hand-written lexical selection rules.

\section{Applying techniques like this to neural machine translation}
During the course of this work, the field of machine translation has undergone
a dramatic shift, in which statistical MT research, and in many cases,
practice\cite{gnmt}, has moved from phrase-based and tree-based SMT systems to
models based on neural networks.

It may not be immediately useful to add explicit CL-WSD classifiers to a neural
MT architecture, although this is an empirical question.  In a sense, though,
we can say that NMT systems are already performing CL-WSD; they have a
representation of the whole input sentence available while making output
decisions. This vector representation is similar to the the doc2vec
representations discussed in Chapter \ref{chap:monolingual}, but is learned
specifically for the translation task, and much deeper recurrent networks are
used for NMT. The sentence-encoding process in neural machine translation
automates much of the feature engineering work that would go into building a
CL-WSD system.

However, many of the difficulties addressed in this work still apply in the
neural machine translation setting. We still must address the issue of how to
leverage the available corpora and tools for resource-rich source languages,
when we have little available bitext. Can source-language parsers be integrated
with NMT? Will this help when translating into under-resourced languages? How
can other existing NLP tools be applied, such as monolingual WSD?

In our CL-WSD setting, we did not find immediate advantages when using neural
embeddings based on comparatively large source-language corpora. But can these
monolingual source-language resources be used for NMT?

There are a number of open questions in neural machine translation; there do
not seem to be widely-accepted approaches for leveraging existing resources to
improve translation into under-resourced languages. ... %% XXX working here

%% Maybe mention the multilingual NLP paper here?
There has already been significant work on multilingual neural machine
translation \cite{TACL1081}


\section{Building resources for Guarani and other under-represented languages}
\label{sec:crowdsourcing}

While we have explored techniques in this work that allow us to lean
somewhat on the resources that we have available for resource-rich source
languages, a clear way to improve translation for currently under-resourced
languages is to make them less under-resourced. Languages like Guarani and
Quechua have a comparable number of speakers as some relatively resource-rich
European languages, as well as engaged activist communities. For example,
Icelandic has fewer than a million speakers... XXX maybe pick a different
example
What about Danish? How many Danish speakers?
While this work has focused on languages spoken in South America, there are
languages around the world with similar situations: millions or possibly many
millions of speakers, but relatively little text on the web (thus far), and no
easily available MT or other good NLP tools.

%% XXX working here
These languages are not yet broadly used in publications on the web,
Internet usage is spreading quickly throughout the world, and
the speakers of these languages are coming online, and . There are many languages in
the world with similar 

There have been fairly successful campaigns by technologists to work with
speakers of these languages to build resources for them.
%% XXX sentence needs work
For example, Mozilla Paraguay managed to localize the Firefox web browser for
Guarani, with the help of Guarani-speaking volunteers. Localizing an
application as complex as a web browser is an enormous task, requiring the
translation of XXX sentence-length messages; also notably, this task requires
choosing appropriate Guarani-language terms for technical concepts.
%% XXX needs citation, also when did this happen?

As a success story directly pertinent to machine translation, in 2013, Google
ran a crowdsourcing campaign in New Zealand that managed to collect
enough training data to build a phrase-based SMT system for the Māori
language\footnote{Post on the Google New Zealand blog:
\url{https://newzealand.googleblog.com/2013/12/kua-puta-google-whakamaori-ki-te-reo.html}}

%% XXX this needs to be reworked for sure


We started some efforts along these lines, but a more sustained effort is
needed. We (the author, working together with Alberto Samaniego and Taylor
Skidmore, directed by Michael Gasser) prototyped two websites for collecting
Guarani and Spanish-Guarani language resources, but these have not been used
beyond the prototype stage.
The first website was called ``Tahekami", which means \emph{let's search
together} in Guarani. Tahekami\footnote{Prototype code at
\url{http://github.com/hltdi/gn-documents}} is a repository of Guarani and
bilingual documents that allows full-text search and browsing documents by tag.
Our initial version of the site contained a collection of masters theses from
the \emph{Ateneo de Lengua y Cultura Guaraní}.
We developed a second website, called ``Guampa" \footnote{A ``guampa", in
Paraguay, is the cup from which one drinks yerba mate or tereré. The term
``guampa" is also local to Paraguay; in other parts of South America, the
container itself is called a ``mate". The Guampa software is available at
\url{https://github.com/hltdi/guampa}}, is a bilingual wiki, which was designed
to be used by Guarani speakers and learners to collaboratively translate
documents from Spanish to Guarani or vice-versa. We presented an initial version
of this software at LREC 2014\cite{RUDNICK14.151}. This is meant to serve at
least three purposes: helping Guarani-language learners practice and get
feedback on their translations, creating more Guarani-language documents for the
web (we started initially with translating Spanish Wikipedia), and building
bitext corpora for training MT systems.

Michael Gasser is developing successors to these websites, in the form of
\emph{mitmita} and \emph{mainumby}, online computer-aided translation systems

In the medium-term, this website will get an integrated ability to search
a translation memory and automatic suggestions from a machine translation
system\footnote{Features described in a presentation in Spanish here:
\url{http://www.cs.indiana.edu/~gasser/Taller2013/} ; English-language similar
presentation: \url{http://tinyurl.com/alexr-clingding-guarani} }
. While these features will be both useful and present a number of
interesting research questions, they are outside the scope of this
dissertation.
