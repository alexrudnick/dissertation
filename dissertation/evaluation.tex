\chapter{Data Sets, Tasks, Software and Evaluation}
\label{chap:evaluation}
In order to evaluate our CL-WSD approaches and their effects on translation
systems, we will need to have a basis for comparison between our proposed
techniques, sensible baselines, and results reported by other researchers.

In this chapter, I describe the tasks and data sets that we examine for the
rest of the dissertation, as well as the basic version of the Chipa software,
which are extended in a variety of directions in subsequent chapters.

\section{Measuring CL-WSD Classification Accuracy}
One straightforward \emph{in vitro} approach for evaluating a CL-WSD system is
to measure classification accuracy over pre-labeled data. Strictly speaking, we
do not have pre-labeled data: our bitext does not come with sub-sentential
alignments. But automatic word alignments provide a good approximation, as long
as our sentence alignments (or verse alignments, for Bible text) are accurate.
For the purposes of this work, we will assume that the automatic word-level
alignments are correct, putting in our best effort preprocessing the available
text so that the aligner can produce useful output.

Using our automatically-aligned bitext as labeled data allows us to closely
mirror the lexical selection task faced by an MT system while translating
running text. We can train our classifiers for many different word types, but
we will generally not have training examples available for all words in the
input at test time. This is a problem faced by data-driven NLP systems broadly.

For comparison with other work, we can also run our systems on the SemEval
shared task test sets, which are publicly available. Our task here is framed in
the same way as the CL-WSD shared tasks from 2010 and 2013, so measuring
performance on these test sets allows a straightforward comparison
between the variations explored in this work and several other CL-WSD systems
from recent years. These test sets are limited in scope, however, and will
only demonstrate Chipa's performance for translating individual English nouns.
It is also worth noting that our more immediate practical goal is to aid
translation from Spanish into lower-resourced languages, and the resources that
we can use to analyze an input English sentence will be different from those
for Spanish.

\TODO{this means we have to actually run the latest Chipa on the SemEval test sets too}

\section{Measuring MT Improvements}
We will additionally want to conduct \emph{in vivo} evaluations of our CL-WSD
techniques as applied to running MT systems.  Here we can use standard
approaches for evaluating MT, such as BLEU and METEOR scores, or simply show
that where word choices differ from the application of CL-WSD, the changes are
improvements.

For these experiments, we sample sentences from the available bitext --
particularly ones that contain polysemous words for which we can train
classifiers! -- and run the MT systems both with and without Chipa enabled.
These experiments are described in more detail in
Chapter~\ref{chap:integration}, where I also discuss how to integrate Chipa
into the different machine translation packages.

\section{Data Sets and Preprocessing}
The largest corpus that we have available for all of our source and target
languages is the Bible. There are translations available for many different
languages, and while these were not always produced by native speakers, the
translators are often driven by missionary zeal to produce high-quality
translations~\cite{DBLP:journals/lre/ResnikOD99}, so we can be reasonably
confident of the (linguistic) accuracy of our text.

In this work, we focus on one Bible translation per language. For Spanish, we
use the Reina-Valera translation (1995 edition), which I was able to scrape
from a Bible study website. Our Guarani translation, \emph{Ñandejara Ñe'e}
(1997 edition) was scraped from the same site. Our Quechua version (the 2004
translation published by the Peruvian Bible Society) was provided by Chris Loza
and Rada Mihalcea; the preparation of the Quechua corpus is described in Loza's
masters thesis \cite{chrisloza}. For English, we use the public domain World
English Bible translation.
While there are a large number of translations available online, different
``Bible societies" own the associated copyrights and thus redistribution of the
complete texts is often restricted \cite{MAYER14.220.L14-1215}.

\subsection{Preprocessing}
There is a nontrivial amount of preprocessing required in order to get our
Bible text into a format suitable for our tools.  This is largely due to the
varying markup formats used by different translation groups.
For each of the formats and translations, we need to understand its formatting
enough to know which text comes from which book, chapter, and verse number.
This triple uniquely identifies a unit of text, and verse numbers are nearly
standardized across translations.  There are a few exceptions, however:
translations produced by different religious traditions may include different
books. Most notably, Catholic editions have a superset of the books found in
modern Protestant editions, and include slightly different chapters.
Additionally, in some translations, such as our Guarani edition, a few verses
have been combined into a single segment for a more natural translation.

In any case, if a particular book/chapter/verse is present in two Bibles, then
the two verses are very likely translations of one another. Once we find all of
the matching verses, we can build a bitext corpus suitable for use in our
pipeline.

Our English translation is distributed in a format called USFM (Unified
Standard Format Markers), which is a markup language developed by a working
group of Bible translators and used widely by the Bible-related software
community.
\footnote{See \url{http://paratext.org/about/usfm} for more about USFM. USFM is
widely deployed; the website from which we scraped the Spanish and Guarani
corpora appears to render its HTML from a USFM source.  There is an entire
community of Bible software developers, and it has a wing that advocates Open
Source software and translations unencumbered by copyright.  One could delve
arbitrarily deeply into the history of religious-text translators and their
relationships with technology and copyright, but one has an NLP dissertation to
write.}
While there are a number of tools that consume this format, I did not find one
that handles our particular use case of stripping metadata and simply mapping
from verses to flat text, so I wrote a short script to parse USFM and produce
text in an easily-alignable format.

Our Spanish and Guarani corpora are extracted from HTML pages scraped from an
online Bible study website. In practice, the scraping was done by predicting
the URLs for each chapter of each book and requesting those URLs
programmatically. We then extract the text from the saved HTML pages with a
Python script and the BeautifulSoup library for HTML parsing.
\footnote{\url{http://www.crummy.com/software/BeautifulSoup/}}
As a side note, since websites change over time and we
downloaded the Guarani translation at an earlier date (from a mobile version of
the site that is no longer available), the HTML takes a significantly different
structure in the Spanish and Guarani editions, so they require different
versions of the script for preprocessing.

Our Quechua translation came in an easily parseable format, with individual
verses already identified by Loza and Mihalcea; for this corpus, very little
preprocessing was necessary before word-level alignment.

Each of the different formatting schemes uses its own coding to identify the
different books of the Bible, so when producing output for alignment, we must
map to a standard encoding. For example, our Quechua edition marks the book of
Lamentations with the numerical code $31$ (it is the thirty-first book in
modern Catholic editions), but in the USFM markup for the English translation,
we find a header with the string ``Lamentations". For our Spanish and Quechua
editions from the web, we find the code ``LAM" in the markup. In any case, we
map each of these identifiers to a single code ``Lam", so that we can match
books, chapters and verses across translations.

\subsection{Morphological Analysis}
\label{sec:guaranima}

For each of our languages, whether on the source or target side, in addition to
tokenizing, lowercasing and verse-alignment, we extract the lemmas (the
citation forms, normalized with respect to inflection) from each surface word.
Especially when working with smaller data sets and morphologically rich
languages, this is an important step; working primarily with lemmas rather than
surface-form words allows us to group, for example, the plural form of a word
with its singular.

For English and Spanish, we use the FreeLing suite of NLP tools
\cite{padro12} to extract lemmas. FreeLing provides a variety of analyses,
including tokenization, sentence splitting, multi-word expression and named
entity detection, part-of-speech tagging and parsing.  We start out using just
a few of these tools -- initially only tokenization and lemmatization. We
discuss making use of more of them in Chapter \ref{chap:monolingual},
leveraging the quality NLP tools that we have for our resource-rich source
languages.

The use of FreeLing for English is a noted improvement over initial
experiments, which used the WordNet lemmatizer and the default NLTK
part-of-speech tagger. The WordNet lemmatizer especially has a fairly small
vocabulary, did not provide a good strategy for dealing with unknown words, and
could only address nouns, verbs, and adjectives.

For Guarani and Quechua, we use Michael Gasser's ParaMorfo and AntiMorfo
analyzers.\footnote{Morphology software for Guarani, Quechua, Spanish, and
other languages is available at
\url{http://www.cs.indiana.edu/~gasser/Research/software.html}} Guarani text is
analyzed with ParaMorfo 1.1, and Quechua with AntiMorfo 1.2.  These packages
are based on software originally developed for Ethiopian Semitic languages
\cite{gasser:eacl09}, and use cascades of finite-state transducers (FSTs),
which is a common approach in morphological analysis \cite{beesley+karttunen}.
ParaMorfo and AntiMorfo use weighted FSTs to handle long-distance dependencies
between morphemes, but rather than having weights correspond to probabilities
to be combined with multiplication, the FSTs are weighted with feature
structures that are combined via unification. This approach was originally
introduced by Amtrup \cite{amtrup:03}. In an FST weighted with feature
structures, the result of a successful traversal is the unification of the
feature structure ``weights'' on the traversed arcs, as well as an output
string. All possible paths through the FST are searched, though many of these
paths will not lead to accepting states, or will fail due to unification
conflicts.  Because a feature structure is accumulated during the process of
transduction, each traversal through the transducer retains a memory of where
it has been, permitting the incorporation of long-distance constraints such as
those relating the negative prefix and suffix of Guarani verbs.

Here the result of morphologically analyzing a word is a root and a feature
structure representing the grammatical features of the word.  For the basic
version of Chipa, we are only concerned with the lemmatized forms of the words
in our corpora, so we ignore the grammatical features for now.  In cases of
morphological ambiguity, which is to say cases where a surface form could be an
inflection of multiple distinct lemmas, we maintain this ambiguity rather than
trying to disambiguate from context.  The different possible lemmas are
separated by a slash; there are examples of this in
Section~\ref{sec:exploring}.

A familiar example of morphological ambiguity in Spanish is that \emph{ir} 'to
go' and \emph{ser} 'to be' share their preterite-tense forms; this is a fairly
common phenomenon. However, the FreeLing analysis tools can typically
(heuristically) resolve these ambiguities for us. When analyzing Guarani and
Quechua, however, the ambiguities are maintained.

\subsection{Alignment}
As a precaution against verses that are not close translations, or perhaps have
combined several parts of the text together into one verse on only one side, we
run the cdec filtering tool (\texttt{filter-length.pl}) with its default
settings, which checks for unusual length disparities in the bitext. This ends
up removing roughly 7\% of the verses, but manual inspection shows that these
are often very loose translations, or that additional material is present on
one side.
\TODO{7\% of the verses for which languages?}

Having tokenized, lowercased, verse-aligned and lemmatized, our corpora, we are
ready to extract word-level alignments.
For this we use the \texttt{fast\_align} tool from cdec
\cite{dyer-EtAl:2010:Demos}, with its default settings\footnote{With the
command given at \url{http://www.cdec-decoder.org/guide/fast_align.html}} and
the lemmatized text as input.
\texttt{fast\_align} runs several iterations of a variant of IBM
Models 1 and 2, with a prior encouraging diagonal alignments. While running, it
tunes the parameters on the priors, and having learned a translation model,
outputs the single most likely one-to-many word alignments, such that each
source language token is linked with zero or more target-language tokens in the
corresponding verse.

\TODO{add a clear example alignment here, maybe a word aligned to a multi-word
expression}

\section{Exploring the Bitext}
\label{sec:exploring}
Even using only the Bible as bitext, we can find a substantial number of
training examples for many common word types. Some of these most common words
in the text are proper names or exhibit only one translation in the target
language, but for the most part we see, through the aligned bitext, that
the most common words are polysemous.
To take a few salient examples from the Spanish-English aligned text,
the verb \emph{hacer} can translate in a number of different ways: 'do',
'make', 'cause'; for \emph{decir}, we must choose between 'say', 'tell' or
'speak'; \emph{mujer} can mean either 'wife' or 'woman'; and \emph{reina} can
translate to 'reign' or 'queen'.  

There are analogous lexical ambiguities when translating from Spanish to
Guarani and Quechua.
For example, the Spanish \emph{pueblo} 'town' or 'people' can translate to
\emph{llaqta} 'town/city', or \emph{runa} 'person'.
For translating from Spanish to Guarani, we see the verb \emph{volver}
'turn/return/repeat' translated as \emph{jey} 'again', but also as \emph{jere}
'turn'.

Figure~\ref{fig:mostcommon-en-es} gives the most common lemmas used in our
corpus for the four languages, along with their counts. In
Figure~\ref{fig:mostcommon-es-translations}, we see common lemmas from
Spanish along with their most likely translations into English, Guarani and
Quechua (as extracted from the bitext). For the purposes of this work, we will
consider words to be in-vocabulary if they appear at least fifty times in the
training corpus; we also do not include punctuation marks and stopwords (as
defined by the default NLTK stopword lists for English and Spanish) other than
common verbs.
%% XXX: magic number. Do we need to argue about fifty? What if we went down to
%% forty? Lower than that and this looks pretty ridiculous.

\TODO{update based on most recent preprocessing pipeline}

\begin{figure*}
  \begin{tiny}
  \begin{centering}
  \begin{tabular}{|r|c|c|}
    \hline
    rank & word type & count \\
    \hline
1 & be & 23542 \\
2 & have & 9389 \\
3 & say & 6664 \\
4 & yahweh & 6508 \\
5 & shall & 4413 \\
6 & god & 4112 \\
7 & come & 3603 \\
8 & son & 3303 \\
9 & go & 2985 \\
10 & do & 2799 \\
11 & king & 2744 \\
12 & one & 2547 \\
13 & israel & 2476 \\
14 & make & 2349 \\
15 & day & 2246 \\
16 & man & 2190 \\
17 & people & 2052 \\
18 & house & 2050 \\
19 & give & 1997 \\
20 & child & 1902 \\
21 & take & 1843 \\
22 & hand & 1793 \\
23 & father & 1782 \\
24 & land & 1758 \\
25 & men & 1518 \\
26 & also & 1456 \\
27 & let & 1386 \\
28 & bring & 1384 \\
29 & thing & 1375 \\
30 & lord & 1374 \\
31 & know & 1328 \\
32 & us & 1326 \\
33 & may & 1290 \\
34 & behold & 1289 \\
35 & city & 1233 \\
36 & therefore & 1220 \\
37 & word & 1195 \\
38 & speak & 1187 \\
39 & even & 1107 \\
40 & like & 1106 \\
41 & servant & 1073 \\
42 & name & 1060 \\
43 & see & 1037 \\
44 & offering & 1000 \\
45 & away & 1000 \\
46 & place & 993 \\
47 & david & 992 \\
48 & great & 936 \\
49 & among & 932 \\
50 & jesus & 930 \\
    \hline
  \end{tabular}
  \quad
  \begin{tabular}{|r|c|c|}
    \hline
    rank & word type & count \\
    \hline
1 & ser & 8436 \\
2 & haber & 8418 \\
3 & jehová & 6515 \\
4 & decir & 6006 \\
5 & hijo & 4955 \\
6 & dios & 4164 \\
7 & estar & 3925 \\
8 & hacer & 3872 \\
9 & tierra & 2832 \\
10 & rey & 2676 \\
11 & israel & 2445 \\
12 & hombre & 2418 \\
13 & tener & 2276 \\
14 & día & 2146 \\
15 & casa & 2056 \\
16 & dar & 2053 \\
17 & entonces & 2026 \\
18 & ir/ser & 1967 \\
19 & pueblo & 1918 \\
20 & pues & 1909 \\
21 & si & 1690 \\
22 & vosotros & 1623 \\
23 & así & 1597 \\
24 & mano & 1535 \\
25 & padre & 1521 \\
26 & señor & 1411 \\
27 & delante & 1292 \\
28 & ciudad & 1259 \\
29 & ver & 1241 \\
30 & poner & 1238 \\
31 & venir & 1182 \\
32 & palabra & 1178 \\
33 & tomar & 1105 \\
34 & cosa & 992 \\
35 & david & 976 \\
36 & responder & 957 \\
37 & mujer & 950 \\
38 & volver & 944 \\
39 & poder & 939 \\
40 & grande & 926 \\
41 & hermano & 912 \\
42 & ir & 904 \\
43 & corazón & 883 \\
44 & sacerdote & 873 \\
45 & lugar & 868 \\
46 & nombre & 867 \\
47 & salir & 833 \\
48 & sino & 831 \\
49 & hablar & 829 \\
50 & año & 823 \\
    \hline
  \end{tabular}
  \end{centering}
  \end{tiny}
  \caption{Some of the most common (lemmatized, non-stopword) word types in our
  English and Spanish Bibles}
  \label{fig:mostcommon-en-es}
\end{figure*}

\begin{figure*}
  \begin{tiny}
  \begin{centering}
  \begin{tabular}{|r|p{4.2cm}|p{4.2cm}|p{4.2cm}|}
    \hline
    es & translations (en)                    & translations (gn) & translations (qu) \\
    \hline
ser & be,  will be, it be, shall be              &   hína, niko, mba'e, ramo                                                              &  ka, kanqa, chayqa, kanki \\
haber & have,  there, i have, i                  &   vaekue, {\textlangle}hague, che, {\textlangle}ha'e                                   &  qan, chay, ma/mana, ni \\
%jehová & yahweh,  yahweh s, to, s                &  ñandejára,  jára, tupã, opa/pa                                                        & señor,  señor diosqa, señor diosmi, señor diospa \\
decir & say,  tell, speak, say to                &  'e,  'e ha'e, ha'e, 'e/ha'e                                                           &  ni, chaymi, hina/hinan, ni/nina/ninaku \\
dios & god,  lord, gods, yahweh                  &  tupã,  jára, momba'e, tupã jára                                                       &  diospa, diosqa, dios, diosmi \\
estar & be,  stand, now, behold                  &   \~{i}{i}, ime, hína, iko/ko                                                          &  ka/kasha, kasha, ka, kaq \\
hacer &  do, make, cause, he                     &   {\textlangle}japo, mba'e, haguã, japouka                                             &  ruwa, chay, ruwa/ruway, ruwa/ruwana \\
tierra & land, earth, ground,  country           &   yvy, {\textlangle}hetã, ko yvy, yvy ári                                              &  suyu, hallp'a, ka/kay pacha \\ %% , ka/kay \\
ir/ser & be,  go, come, depart                   &   ha, vaekue, upe, kuéra                                                               &  karqan, ri, ripu, hina/hinan \\
pueblo & people, among,  nation, multitude       &   {\textlangle}hetã, {\textlangle}hetã gua, opavave, israelgua                         & llaqta,  runa, llaq/llaqta, israel runa \\
pues &  for, therefore, so, then                 &   upe, niko, aipórõ, che                                                               &  chay, chaymi, chay hinaqa, chhaynaqa \\
si & if,  if you, but if, whether                &  ramo,  rire, ime, pende                                                               &  chayqa, ma/mana, chaypas, icha \\
así &  so, thus, this, therefore                 &   upe, péicha, kóicha, avei                                                            &  chay, ahi/ahina, chay hina, hina \\
%%padre & father,  parent, his father, father s    &  ru,  ru ypy, ypy, vaekue                                                              & tayta,  yaya, ñawpa tayta, tayta/taytay \\
padre & father,  parent, his father              &  ru,  ru ypy, ypy, vaekue                                                              & tayta,  yaya, ñawpa tayta, tayta/taytay \\
señor & lord, master,  sir, ruler                &  ñandejára,  jára, karai, che jára                                                     &  señor, apu, señorpa, señorníy \\
poner &  put, set, lay, make                     &   mo\~{i}{i}/\~{i}{i}, mo\~{i}{i}, mo\~{i}{i}/ñemo\~{i}{i}/\~{i}{i}, upéi              &  chura, hina, hinaspa, chay \\
%venir & come,  will come, behold, will           &   ju, guah\~{i}{i}{e}, aju/ju, rendápe                                                 &  hamu, chaya/chayamu, hamu/hamuq, chaya \\
%tomar & take,  shall take, took, he take         &   raha, momba'e, {\textlangle}hupi, japyhy                                             &  hap'i, hina, hina/hinan, apa \\
%responder & answer,  say, then, but              &  'e,  'e ha'e, katu, katu 'e                                                           &  kuti/kutichi, ni, chaymi, hina/hinan \\
mujer & woman, wife,  a wife, a woman            &  kuña, {\textlangle}hembireko,  menda, kuñakarai                                       & warmi,  war, warmi/warmiy, qhari \\
volver & return,  turn, again, back              &   jey, jeýta, ju jey, jere                                                             &  kutipu, wakmanta, kuti, kuti/kutimu \\
poder & can,  power, able, could                 &  katu,  pu'aka, ndaikatu, mbarete                                                      &  ati, ati/atiy, ma/mana, atiyniyoq \\
ir & go,  come, will, let                        &   ha, s\~{i}{i}{e}, ha ha, {\textlangle}hasa                                           &  ri, ripu, ri/rina, ri/risa \\
%% lugar & place,  instead, in, place where         &   {\textlangle}henda, {\textlangle}hendague/{\textlangle}hendaguépe/hendague, {\textlangle}henda/ha'e, {\textlangle}hendague/{\textlangle}hendaguépe/rendague  &  ranti, cheqasta, ma, cheqasman \\
salir & go out, come out,  out, go               &  s\~{i}{i}{e},  upe, ha, s\~{i}{i}{e} okápe                                            &  ri, lloqsispa, puriri, hina/hinan \\
%siervo & servant,  slave, male servant, young    &  {\textlangle}hembiguái,  mburuvicha, che, {\textlangle}huvicha                        &  kamachi, kama/kamachi, kama/kamachi/kamachiy, kama \\
judá & judah, jew,  belongs, of judah            &  judá, judagua,  judápe, judágui                                                       & judá, judá suyu,  judapi, judá ayllu \\
mismo &  same, himself, own, myself              &   voi, avei, upe, pete\~{i}{i}                                                         &  kikin, kaq, chay, hina/hinalla \\
% oír & hear, heard, listen,  when                 &  {\textlangle}hendu,  kuaa, {\textlangle}hendu/ndu, japysaka                           & uyari,  uya, uyari/uyarina, uyari/uyariqkuna \\
llevar & bring,  carry, take, bear               &  raha,  {\textlangle}hupi, raha hikuái, hikuái                                         &  apa, pusa, apa/apamu, apari/apariku \\
% hecho & do,  make, done, work                    &   {\textlangle}japo, {\textlangle}japo vaekue, {\textlangle}hembiapo, mba'e            &  ruwa, ru, kama, allinta \\
dicho & say, speak,  tell, word                  &  'e,  'e/ha'e, kóicha 'e, {\textlangle}he'ika                                          & ni,  diosmi ni, apu, diosmi \\
cielo & heaven, sky,  heavens, cloud             &  yvága,  ára, yvate, yvága pe/pegua                                                    & hana/hanaq pacha,  pacha, hana/hanaq, hana/hanaq pa \\
ojo & eye, sight,  in, his eye                   &   {\textlangle}hesa, {\textlangle}hecha, ma'\~{i}{i}{e}, che                           &  ñawi, qhawari, ri/riku, ruwa \\
llegar & come,  have come, reach, when           &  guah\~{i}{i}{e},  guah\~{i}{i}{e} hikuái, ke, ja/mboja/ñemboja                        &  chaya, chaya/chayamu, hamu, cha \\
%quedar & be,  stay, remain, be leave             &   pyta, {\textlangle}hemby, {\textlangle}heja, ndopyta                                 &  kapu/kapun, kanqa, qhepaq, qhepakurqan \\
%aquel & that,  him, will, everyone               &  upe,  pe, upe upe, umiha                                                              & chay,  pipas, haqay, chaypachan \\
%% cada & each, every,  everyone, every man         &   te\~{i}{i}, opa/pa, {\textlangle}he\~{i}{i}/{\textlangle}he\~{i}{i}me/te\~{i}{i}, pete\~{i}{i} te\~{i}{i}    &  sapanka, sapa, sapa/sapan, sapankanku \\
% medio &  middle, among, through, within          &   rupi, mbytépe, apytépe, pende                                                        &  ukhu, ukhupi, chawpi, qankuna \\
entrar & enter into, come, come into, go into, go&  ke,  guah\~{i}{i}{e}, ndoike, hikuái                                                  & hayku,  hayku/haykuna, ri, hay \\
%% llamar & call, name,  whose name, summon         &  {\textlangle}héra, {\textlangle}henói,  {\textlangle}henoika/henoika, {\textlangle}henói/nói                                          &  waq/waqya, sutiyoq, waqya, suti/suticha \\
llamar & call, name, summon                      &  {\textlangle}héra, {\textlangle}henói,  {\textlangle}henoika/henoika, {\textlangle}henói/nói                                          &  waq/waqya, sutiyoq, waqya, suti/suticha \\
%espíritu & spirit,  breath, by, trouble          &  espíritu,  espíritu santo, py'a, pu'aka                                               &  santo espirituq, santo, espiritun, santo espirituqa \\
%monte & mountain, on,  mount, hill country       &  yvyty,  yvyty {\textlangle}hu'ã, ka'aguy, yvyty rupi                                  & orqo,  orqopi, orqoman, orqokuna \\
subir & go up, come up, up,  ascend              &   jupi, ha, s\~{i}{i}{e}, ju                                                           &  wicha, ri, wichari, chay/chayman \\
obra & work, do,  deed, doings                   &   {\textlangle}hembiapo, {\textlangle}japo, mba'e, mba'e {\textlangle}japo             & ruwa,  llank'a, ruwa/ruwana, ruwa/ruway \\
%% puerta & gate, door, at,  threshold              &  {\textlangle}hok\~{i}{i}{e},  k\~{i}{i}{e}, táva {\textlangle}hok\~{i}{i}{e}, {\textlangle}hok\~{i}{i}{e} nguéra          & punku,  hayku/haykuna, punku/punkuta, pun \\
% pecado & sin, iniquity, trespass,  transgression &  angaipa,  {\textlangle}hembiapo vai, vai, {\textlangle}heja rei                       & hucha, huchalli/huchalliku,  hucha/huchaku, hu \\
hija & daughter,  her, her daughter, woman       &  rajy,  kuña, memby, táva                                                              & ususi,  warmi, warmi wawa, llaq/llaqta \\
% junto & by,  together, beside, at                &   {\textlangle}hembe'y, ypýpe, ykére, \~{i}{i}                                         &  qaylla, patapi, kuska, qayllapi \\
dejar & leave,  let, allow, they                 &   {\textlangle}heja, poi, ja, jei                                                      &  kachari, ama, ma/mana, maña/mañana \\
    \hline
  \end{tabular}
  \end{centering}
  \end{tiny}
  \caption{Selected common Spanish word types with their most likely
translations. These were picked for interesting polysemy from the 100 most
common word types.}
  \label{fig:mostcommon-es-translations}
\end{figure*}

\begin{figure*}
  \begin{tiny}
  \begin{centering}
  \begin{tabular}{|r|c|c|c|c|}
    \hline
    es & entropy (en) & entropy (gn) & entropy (qu) \\
    \hline
ser    &     2.49         &      3.90        &       3.25       \\  
haber  &     2.88         &      3.57        &       2.70       \\
decir  &     1.57         &      2.05        &       1.82       \\
dios   &     0.33         &      1.56        &       3.99       \\
estar  &     2.07         &      3.01        &       2.61       \\
hacer  &     4.07         &      2.68        &       2.67       \\
tierra &     2.00         &      2.96        &       3.58       \\
ir/ser &     2.65         &      3.19        &       2.92       \\
pueblo &     0.56         &      3.36        &       3.21       \\
pues   &     3.18         &      3.73        &       2.90       \\
si     &     2.68         &      3.06        &       2.91       \\
así    &     2.95         &      2.73        &       3.27       \\
padre  &     0.53         &      1.48        &       2.60       \\
señor  &     0.78         &      3.15        &       3.38       \\
poner  &     4.32         &      3.05        &       2.93       \\
mujer  &     2.11         &      2.28        &       1.88       \\
volver &     3.89         &      3.59        &       3.65       \\
poder  &     3.51         &      3.12        &       3.36       \\
ir     &     3.49         &      2.96        &       2.77       \\
salir  &     3.43         &      2.40        &       3.91       \\
judá   &     0.23         &      2.07        &       2.81       \\
mismo  &     3.27         &      2.94        &       2.87       \\
llevar &     3.70         &      1.81        &       2.79       \\
dicho  &     1.91         &      2.60        &       2.99       \\
cielo  &     1.32         &      2.21        &       2.13       \\
ojo    &     2.03         &      2.52        &       2.57       \\
llegar &     3.23         &      2.76        &       3.27       \\
entrar &     3.77         &      1.88        &       2.71       \\
llamar &     1.64         &      2.69        &       3.49       \\
subir  &     2.85         &      3.39        &       3.19       \\
obra   &     1.99         &      3.27        &       3.42       \\
hija   &     0.35         &      2.33        &       2.29       \\
dejar  &     4.03         &      2.67        &       2.80       \\
    \hline
  \end{tabular}
  \end{centering}
  \end{tiny}
  \caption{Common Spanish word types and the entropy, in bits, faced by a
  system that must choose among the possible alternatives} 
  \label{fig:mostcommon-es-entropy}
\end{figure*}

Using larger bitexts of course will allow us to construct training and test
sets for a broader vocabulary, and with better statistical support for the
words already present. However even when working with the Bible, we
have at least fifty uses of over a thousand different lemmas, for English and
Spanish, as shown in Figure \ref{fig:mostcommon-en-es}.

\TODO{For comparison, do we want to include the stats for Europarl here too? Or
maybe we could put that in the ``multilingual" chapter?}

\section{Baseline Chipa System}
At its core, the Chipa software takes in a word-aligned bitext corpus, with
annotations for the source tokens. It then trains CL-WSD classifiers for
source-language word types on demand. 

The software holds all of the available bitext in memory. On request, it
constructs a training set for learning to disambiguate a given word
by retrieving all sentences that contain that word,
finding the instances of that word and its aligned translations, and extracting
features (see Figure~\ref{fig:baselinefeatures}) from the source side and its
annotations.
If a source-language word has been seen aligned to only one target-language
type, then this is simply noted, and if the source word is not present in the
training data, then that word is marked as out-of-vocabulary. In these latter
two cases, we skip building a classifier for that word, since there is no
ambiguity present in our examples.

Since source-language tokens may be NULL-aligned (i.e., not all words in the
source text will have corresponding words in the target text), both in the
training data and in translations, chipa provides the option to request
classifiers that consider NULL as a valid label for classification, or not, as
appropriate for the translation application. We here report classification
accuracies for both settings.

Memory permitting, Chipa classifiers are kept cached for later usage. Chipa can
also be run as a server, providing an interface whereby client programs can
request CL-WSD decisions over remote procedure calls (RPC).

Chipa's classifiers are trained with the scikit-learn machine learning toolkit
\cite{scikit-learn} for Python and its associated NLTK interface, though in
earlier versions, we used the megam package \cite{daume04cg-bfgs}, also through
NLTK.  By default, we use Logistic Regression classifiers (also known as
Maximum Entropy), with the default scikit-learn settings.
Maximum entropy classifiers are well-suited to this sort of classification
task, as they are robust to adding large numbers of features, even
highly-correlated ones \cite{nigam1999using}.
Furthermore, because we have a large number of features but a relatively small
number of samples per classifier, we train with L1 regularization rather than
L2~\cite{ng2004feature}.
We can also set a regularization parameter during training, to encourage
more parsimonious solutions and thus avoid overfitting.
Here by default we set the regularization parameter to $C=1.0$.

%% XXX working here

We have also tried a variety of classification algorithms; scikit-learn makes
experimentation with different classifiers and parameter settings
straightforward. We have tried random forests and linear support vector
machines, and of course compare these to the most-frequent-sense baseline.

\TODO{Report results with a few different regularization settings}
\TODO{Report results with SVMs and random forests too.}

\begin{figure*}
  \begin{centering}
  \begin{tabular}{|r|p{11cm}|}
    \hline
    name          & description  \\
    \hline
    \texttt{bagofwords}    & a feature counting each lemma in the source sentence \\
    \hline
    \texttt{bagofsurface}  & like \texttt{bagofwords}, but with surface forms \\
    \hline
    \texttt{window}       & a binary feature for each of the lemmas in the immediately surrounding three-word context window \\
    \hline
    \texttt{surfacewindow} & like \texttt{window}, but with surface forms \\
    \hline
  \end{tabular}
  \end{centering}
  \caption{Features for the baseline Chipa system}
  \label{fig:baselinefeatures}
\end{figure*}

\section{Source-side annotations}
\label{sec:annotations}
In order to gracefully include a variety of features and build on
any available analysis tools for the source language, Chipa's input format and
feature functions allow for arbitrary annotations on source-language tokens.

Chipa's input file format describes one token per line, with fields split by
tabs.  The first field of a line is a token's lemma, and the second field is
its surface form.  Following this are an arbitrary number of annotations for
that token, which may encode things such as part-of-speech, dependency
relations, Sentence boundaries are indicated by blank lines. An annotated
sentence with only one annotation per token might look like this, for example:

\begin{figure*}
\raggedright \texttt{\\
the	The	pos=DET \\
quick	quick	pos=ADJ \\
brown	brown	pos=ADJ \\
fox	fox	pos=NOUN \\
jump	jumped	pos=VERB \\
over	over	POS=ADP \\
the	the	POS=DET \\
lazy	lazy	POS=ADJ \\
sleep sleeping	POS=VERB \\
dog	dog	POS=NOUN \\
.	.	POS=. \\
  }
  \caption{Example annotated sentence.}
  \label{fig:quickbrownfox}
\end{figure*}

Chipa has been developed with a number of tooks that both consume and produce
this format, typically taking in sentences annotated in this way, calling
another NLP tool to generate more annotations, and then adding the results to
those annotations already present.

\section{Classification Results for the Baseline System}

\TODO{insert a bunch of numbers here}

\begin{itemize}
\item en-es
\item es-en
\item es-gn
\item es-qu
\end{itemize}

\TODO{Words in Spanish for which we gain the most by training a classifier --
measured as the difference in accuracy between MFS}
