\chapter{Data Sets, Tasks, Software and Evaluation}
\label{chap:evaluation}
In order to evaluate our CL-WSD approaches and their effects on translation
systems, we will need to have some basis for comparison between the various
techniques that we would like to evaluate, sensible baselines, and results
reported by other researchers.

So in this chapter, I describe the tasks and data sets that we will be
examining for the rest of the dissertation, as well as the basic version of the
Chipa software, which will be extended in subsequent chapters.

\section{Measuring CL-WSD Classification Accuracy}
One clear \emph{in vitro} approach for measuring the success of a CL-WSD system
is to report its classification accuracy on pre-labeled data. Strictly
speaking, we do not have pre-labeled data: our bitext does not
come with sub-sentential alignments. But automatic word alignments provide
a good approximation, as long as our sentence (or verse, for Bible text)
alignments are accurate. For the purposes of this work, we will assume that the
automatic alignments are correct, putting in our best effort preprocessing
the available text so that the aligner can produce sensible output.

Using our automatically-aligned bitext as labeled data allows us to approximate
the task faced by an MT system trying to do lexical selection for running text,
since we can train our classifiers for many different word types. We do not
have sufficient training data to build classifiers for every possible word, but
this is a problem faced by data-driven NLP systems broadly.

For comparison with other work, we can also run our systems on the SemEval
shared task test sets, which are publicly available. Our task here is framed in
the same way as the CL-WSD shared tasks from 2010 and 2013, so measuring
performance on these test sets will provide a straightforward comparison
between the variations explored in this work and several other CL-WSD systems
from recent years.  These test sets are limited in scope, however, and will
only demonstrate Chipa's performance for translating individual English nouns.
It is also worth noting that our more immediate practical goal is to aid
translation from Spanish into lower-resourced languages, and the resources that
we can use to analyze an input English sentence will be different from those
for Spanish.

\section{Measuring MT Improvements}
We will additionally want to conduct \emph{in vivo} evaluations of our CL-WSD
techniques as applied to lexical selection in running MT systems.  Here we can
use standard approaches for evaluating MT, such as BLEU and METEOR scores.

For these experiments, we sample sentences from the available bitext --
particularly ones that contain polysemous words for which we can train
classifiers! -- and run the MT systems both with and without Chipa enabled.
These experiments are described in more detail in
Chapter~\ref{chap:integration}, where I also discuss how to integrate Chipa
into the different machine translation packages.

\section{Data Sets and Preprocessing}
The largest corpus that we have available for all of our source and target
languages is the Bible. There are translations available for many different
languages, and while these are not always done by native speakers,
the translators are often driven by missionary zeal to get the best possible
translation~\cite{DBLP:journals/lre/ResnikOD99}, so we can be confident that
our Bibles are at least fairly good examples of our target languages.

Our corpora came from a number of different sources. For Spanish, we use the
Reina-Valera translation (1995 edition), which I was able to scrape from a
Bible study website. Our Guarani translation, \emph{Ñandejara Ñe'e} (1997
edition) was scraped from the same site.  Our Quechua version (the 2004
translation published by the Peruvian Bible Society) was provided by Chris Loza
and Rada Mihalcea; the preparation of the Quechua corpus is described in Loza's
masters thesis \cite{chrisloza}. For English, we use the public domain World
English Bible translation.
While there are a large number of translations available online, different
``Bible societies" own the associated copyrights and thus redistribution of the
complete texts is often restricted \cite{MAYER14.220.L14-1215}.

\subsection{Preprocessing}
There is a nontrivial amount of preprocessing that must be done in order to get
our Bible text into a format suitable for our tools.
This is largely due to the various markup formats used for different
translations in different languages. For each of the formats and translations,
we need to understand its formatting enough to know which text comes from
which book, chapter, and verse number. This triple uniquely identifies a
unit of text, and verse numbers are nearly standardized across translations.
There are a few exceptions, however: translations produced by different
religious traditions may include different books (Catholic editions have
a superset of the books found in most modern Protestant editions, for example),
and slightly different chapters. Additionally, in some translations, such as
our Guarani edition, a few verses have been combined into a single segment for
a more natural translation.

In any case, if a particular book/chapter/verse is present in two Bibles, then
the two verses are very likely translations of one another. Once we find all of
the matching verses, we can build a bitext corpus suitable for use in our
pipeline.

Our English translation is distributed in a format called USFM (Unified
Standard Format Markers), which is a markup language developed by a working
group of Bible translators and used widely by the Bible-related software
community.
\footnote{See \url{http://paratext.org/about/usfm} for more about USFM. USFM is
widely deployed; the website from which we scraped the Spanish and Guarani
corpora appears to render its HTML from a USFM source. 
There is an entire community of Bible software developers, and it has a wing
that advocates Open Source and translations unencumbered by copyright.  One
could delve arbitrarily deeply into the history of religious-text translators
and their relationships with technology and copyright, but one has an NLP
dissertation to write.}
While there are a number of tools that consume this format, I did not find one
that handles our particular use case of stripping metadata and simply mapping
from verses to flat text, so I wrote a short script to parse USFM and produce
text in an easily-alignable format.

Our Spanish and Guarani corpora are extracted from HTML pages scraped from an
online Bible study website. In practice, the scraping was done by predicting
the URLs for each chapter of each book and requesting those URLs
programmatically. We then extract the text from the saved HTML pages with a
Python script and the BeautifulSoup library for HTML parsing.
\footnote{\url{http://www.crummy.com/software/BeautifulSoup/}}
As a side note, since websites change over time and we
downloaded the Guarani translation at an earlier date (from a mobile version of
the site that is no longer available), the HTML takes a significantly different
structure in the Spanish and Guarani editions, so they require different
versions of the script for preprocessing.

Our Quechua translation came in a straightforward format, with individual
verses already identified and ready for alignment.

Each of the different formatting schemes uses its own coding to identify the
different books of the Bible, so when producing output for alignment, we must
map to a standard encoding. For example, our Quechua edition marks the book of
Lamentations with the numerical code $31$ (it is the thirty-first book in
modern Catholic editions), but in the USFM markup for the English translation,
we find a header with the string ``Lamentations". For our Spanish and Quechua
editions from the web, we find the code ``LAM" in the markup. In any case, all
of these encodings are mapped to a single code ``Lam", so that we can match
books, chapters and verses across translations.

\subsection{Morphological Analysis}
\label{sec:guaranima}

For each of our languages, after tokenizing, lowercasing and verse-alignment,
we extract the lemmas (citation forms) for both source and target languages.
Especially when working with smaller data sets, this is an important step;
working primarily with lemmas rather than surface-form words allows us to
group, for example, the plural form of a word with the singular.

For English, we use the WordNet lemmatizer, coupled with the default NLTK
part-of-speech tagger. This maps any word type found in WordNet to its citation
form; if a word is not found, or is not a noun, verb, or adjective, we simply
return its surface form.

We analyze the other three languages with Michael Gasser's ParaMorfo and
AntiMorfo analyzers.\footnote{Morphology software for Guarani, Quechua,
Spanish, and other languages is available at
\url{http://www.cs.indiana.edu/~gasser/Research/software.html}} Spanish and
Guarani are analyzed with ParaMorfo 1.1, and Quechua with AntiMorfo 1.2. These
packages are based on software that Gasser originally developed for Ethiopian
Semitic languages \cite{gasser:eacl09}, and use cascades of finite-state
transducers (FSTs), which is a common approach in morphological analysis
\cite{beesley+karttunen}. This software uses weighted FSTs to handle
long-distance dependencies between morphemes, but rather than having weights
correspond to probabilities to be combined with multiplication, these FSTs are
weighted with feature structures that are combined via unification.  This
approach was originally introduced by Amtrup \cite{amtrup:03}. In an FST
weighted with feature structures, the result of a successful traversal is the
unification of the feature structure ``weights'' on the traversed arcs, as well
as an output string. Because a feature structure is accumulated during the
process of transduction, the transducer retains a memory of where it has been,
permitting the incorporation of long-distance constraints such as those
relating the negative prefix and suffix of Guarani verbs.

Here the output of the morphological analysis of a word is a root and a feature
structure representing the grammatical features of the word.  For the basic
version of Chipa, we are only concerned with the lemmatized forms of the words
in our corpora, so we ignore the grammatical features for now.
In cases of morphological ambiguity, which is to say cases where a surface form
could be an inflection of two different lemmas, we maintain this ambiguity
rather than trying to do morphological disambiguation and deciding from context
which lemma was in use. The different possible lemmas are separated by a slash;
there are examples of this in Section~\ref{sec:exploring}. A familiar example
of morphological ambiguity in Spanish is that \emph{ir} 'to go' and \emph{ser}
'to be' share their preterite-tense forms; this is a fairly common phenomenon.

\subsection{Alignment}
As a precaution against verses that are not close translations, or perhaps have
combined several parts of the text together into one verse on only one side, we
run the cdec filtering tool (\texttt{filter-length.pl}) with its default
settings, which checks for unusual length disparities in the bitext. This ends
up removing roughly 7\% of the verses, but manual inspection shows that these
are often very loose translations, or that additional material is present on
one side.

Having tokenized, lowercased, verse-aligned and lemmatized, our corpora, we are
ready to extract word-level alignments.
For this we use the \texttt{fast\_align} tool from cdec
\cite{dyer-EtAl:2010:Demos}, with its default settings\footnote{With the
command given at \url{http://www.cdec-decoder.org/guide/fast_align.html}} and
the lemmatized text as input.
\texttt{fast\_align} runs several iterations of a variant of IBM
Models 1 and 2, with a prior encouraging diagonal alignments. While running, it
tunes the parameters on the priors, and having learned a translation model,
outputs the single most likely one-to-many word alignments, such that each
source language token is linked with zero or more target-language tokens in the
corresponding verse.

%% XXX: it would be cool to have an example alignment here, maybe a word
%% aligned to a multi-word expression

\section{Exploring the Bitext}
\label{sec:exploring}
Even using only the Bible as bitext, we can find a substantial number of
training examples for many common word types. Some of these most common words
in the text are proper names or exhibit only one translation in the target
language, but for the most part we see, through the aligned bitext, that
the most common words are polysemous.
To take a few salient examples from the Spanish-English aligned text,
the verb \emph{hacer} can translate in a number of different ways: 'do',
'make', 'cause'; for \emph{decir}, we must choose between 'say', 'tell' or
'speak'; \emph{mujer} can mean either 'wife' or 'woman'; and \emph{reina} can
translate to 'reign' or 'queen'.  

There are analogous lexical ambiguities when translating from Spanish to
Guarani and Quechua.
For example, the Spanish \emph{pueblo} 'town' or 'people' can translate to
\emph{llaqta} 'town/city', or \emph{runa} 'person'.
%% For Guarani, \emph{estar} 'to be' is translated as \emph{iko} 'to dwell'
For Guarani, we see the verb \emph{volver} 'turn/return' translated as
\emph{jey} 'again', but also as \emph{jere} 'turn', which nicely exhibits the
...

%% XXX

Figure~\ref{fig:mostcommon-en-es} gives the most common lemmas used in our
corpus for the four languages, along with their counts. In
Figure~\ref{fig:mostcommon-es-translations}, we see the most common lemmas from
Spanish, along with their most likely translations into English, Guarani and
Quechua. For the purposes of this work, we will consider words to be
in-vocabulary if they appear at least fifty times in the training corpus; we
also do not include punctuation marks and stopwords (as defined by the default
NLTK stopword lists for English and Spanish) other than common verbs.
%% XXX: magic number. Do we need to argue about fifty? What if we went down to
%% forty? Lower than that and this looks pretty ridiculous.

\begin{figure*}
  \begin{tiny}
  \begin{centering}
  \begin{tabular}{|r|c|c|}
    \hline
    rank & word type & count \\
    \hline
1 & be & 23542 \\
2 & have & 9389 \\
3 & say & 6664 \\
4 & yahweh & 6508 \\
5 & shall & 4413 \\
6 & god & 4112 \\
7 & come & 3603 \\
8 & son & 3303 \\
9 & go & 2985 \\
10 & do & 2799 \\
11 & king & 2744 \\
12 & one & 2547 \\
13 & israel & 2476 \\
14 & make & 2349 \\
15 & day & 2246 \\
16 & man & 2190 \\
17 & people & 2052 \\
18 & house & 2050 \\
19 & give & 1997 \\
20 & child & 1902 \\
21 & take & 1843 \\
22 & hand & 1793 \\
23 & father & 1782 \\
24 & land & 1758 \\
25 & men & 1518 \\
26 & also & 1456 \\
27 & let & 1386 \\
28 & bring & 1384 \\
29 & thing & 1375 \\
30 & lord & 1374 \\
31 & know & 1328 \\
32 & us & 1326 \\
33 & may & 1290 \\
34 & behold & 1289 \\
35 & city & 1233 \\
36 & therefore & 1220 \\
37 & word & 1195 \\
38 & speak & 1187 \\
39 & even & 1107 \\
40 & like & 1106 \\
41 & servant & 1073 \\
42 & name & 1060 \\
43 & see & 1037 \\
44 & offering & 1000 \\
45 & away & 1000 \\
46 & place & 993 \\
47 & david & 992 \\
48 & great & 936 \\
49 & among & 932 \\
50 & jesus & 930 \\
    \hline
  \end{tabular}
  \quad
  \begin{tabular}{|r|c|c|}
    \hline
    rank & word type & count \\
    \hline
1 & ser & 8436 \\
2 & haber & 8418 \\
3 & jehová & 6515 \\
4 & decir & 6006 \\
5 & hijo & 4955 \\
6 & dios & 4164 \\
7 & estar & 3925 \\
8 & hacer & 3872 \\
9 & tierra & 2832 \\
10 & rey & 2676 \\
11 & israel & 2445 \\
12 & hombre & 2418 \\
13 & tener & 2276 \\
14 & día & 2146 \\
15 & casa & 2056 \\
16 & dar & 2053 \\
17 & entonces & 2026 \\
18 & ir/ser & 1967 \\
19 & pueblo & 1918 \\
20 & pues & 1909 \\
21 & si & 1690 \\
22 & vosotros & 1623 \\
23 & así & 1597 \\
24 & mano & 1535 \\
25 & padre & 1521 \\
26 & señor & 1411 \\
27 & delante & 1292 \\
28 & ciudad & 1259 \\
29 & ver & 1241 \\
30 & poner & 1238 \\
31 & venir & 1182 \\
32 & palabra & 1178 \\
33 & tomar & 1105 \\
34 & cosa & 992 \\
35 & david & 976 \\
36 & responder & 957 \\
37 & mujer & 950 \\
38 & volver & 944 \\
39 & poder & 939 \\
40 & grande & 926 \\
41 & hermano & 912 \\
42 & ir & 904 \\
43 & corazón & 883 \\
44 & sacerdote & 873 \\
45 & lugar & 868 \\
46 & nombre & 867 \\
47 & salir & 833 \\
48 & sino & 831 \\
49 & hablar & 829 \\
50 & año & 823 \\
    \hline
  \end{tabular}
  \end{centering}
  \end{tiny}
  \caption{Some of the most common (lemmatized, non-stopword) word types in our
  English and Spanish Bibles}
  \label{fig:mostcommon-en-es}
\end{figure*}

\begin{figure*}
  \begin{tiny}
  \begin{centering}
  \begin{tabular}{|r|p{4.2cm}|p{4.2cm}|p{4.2cm}|}
    \hline
    es & translations (en)                    & translations (gn) & translations (qu) \\
    \hline
ser & be,  will be, it be, shall be              &   hína, niko, mba'e, ramo                                                              &  ka, kanqa, chayqa, kanki \\
haber & have,  there, i have, i                  &   vaekue, {\textlangle}hague, che, {\textlangle}ha'e                                   &  qan, chay, ma/mana, ni \\
%jehová & yahweh,  yahweh s, to, s                &  ñandejára,  jára, tupã, opa/pa                                                        & señor,  señor diosqa, señor diosmi, señor diospa \\
decir & say,  tell, speak, say to                &  'e,  'e ha'e, ha'e, 'e/ha'e                                                           &  ni, chaymi, hina/hinan, ni/nina/ninaku \\
dios & god,  lord, gods, yahweh                  &  tupã,  jára, momba'e, tupã jára                                                       &  diospa, diosqa, dios, diosmi \\
estar & be,  stand, now, behold                  &   \~{i}{i}, ime, hína, iko/ko                                                          &  ka/kasha, kasha, ka, kaq \\
hacer &  do, make, cause, he                     &   {\textlangle}japo, mba'e, haguã, japouka                                             &  ruwa, chay, ruwa/ruway, ruwa/ruwana \\
tierra & land, earth, ground,  country           &   yvy, {\textlangle}hetã, ko yvy, yvy ári                                              &  suyu, hallp'a, ka/kay pacha \\ %% , ka/kay \\
ir/ser & be,  go, come, depart                   &   ha, vaekue, upe, kuéra                                                               &  karqan, ri, ripu, hina/hinan \\
pueblo & people, among,  nation, multitude       &   {\textlangle}hetã, {\textlangle}hetã gua, opavave, israelgua                         & llaqta,  runa, llaq/llaqta, israel runa \\
pues &  for, therefore, so, then                 &   upe, niko, aipórõ, che                                                               &  chay, chaymi, chay hinaqa, chhaynaqa \\
si & if,  if you, but if, whether                &  ramo,  rire, ime, pende                                                               &  chayqa, ma/mana, chaypas, icha \\
así &  so, thus, this, therefore                 &   upe, péicha, kóicha, avei                                                            &  chay, ahi/ahina, chay hina, hina \\
%%padre & father,  parent, his father, father s    &  ru,  ru ypy, ypy, vaekue                                                              & tayta,  yaya, ñawpa tayta, tayta/taytay \\
padre & father,  parent, his father              &  ru,  ru ypy, ypy, vaekue                                                              & tayta,  yaya, ñawpa tayta, tayta/taytay \\
señor & lord, master,  sir, ruler                &  ñandejára,  jára, karai, che jára                                                     &  señor, apu, señorpa, señorníy \\
poner &  put, set, lay, make                     &   mo\~{i}{i}/\~{i}{i}, mo\~{i}{i}, mo\~{i}{i}/ñemo\~{i}{i}/\~{i}{i}, upéi              &  chura, hina, hinaspa, chay \\
%venir & come,  will come, behold, will           &   ju, guah\~{i}{i}{e}, aju/ju, rendápe                                                 &  hamu, chaya/chayamu, hamu/hamuq, chaya \\
%tomar & take,  shall take, took, he take         &   raha, momba'e, {\textlangle}hupi, japyhy                                             &  hap'i, hina, hina/hinan, apa \\
%responder & answer,  say, then, but              &  'e,  'e ha'e, katu, katu 'e                                                           &  kuti/kutichi, ni, chaymi, hina/hinan \\
mujer & woman, wife,  a wife, a woman            &  kuña, {\textlangle}hembireko,  menda, kuñakarai                                       & warmi,  war, warmi/warmiy, qhari \\
volver & return,  turn, again, back              &   jey, jeýta, ju jey, jere                                                             &  kutipu, wakmanta, kuti, kuti/kutimu \\
poder & can,  power, able, could                 &  katu,  pu'aka, ndaikatu, mbarete                                                      &  ati, ati/atiy, ma/mana, atiyniyoq \\
ir & go,  come, will, let                        &   ha, s\~{i}{i}{e}, ha ha, {\textlangle}hasa                                           &  ri, ripu, ri/rina, ri/risa \\
%% lugar & place,  instead, in, place where         &   {\textlangle}henda, {\textlangle}hendague/{\textlangle}hendaguépe/hendague, {\textlangle}henda/ha'e, {\textlangle}hendague/{\textlangle}hendaguépe/rendague  &  ranti, cheqasta, ma, cheqasman \\
salir & go out, come out,  out, go               &  s\~{i}{i}{e},  upe, ha, s\~{i}{i}{e} okápe                                            &  ri, lloqsispa, puriri, hina/hinan \\
%siervo & servant,  slave, male servant, young    &  {\textlangle}hembiguái,  mburuvicha, che, {\textlangle}huvicha                        &  kamachi, kama/kamachi, kama/kamachi/kamachiy, kama \\
judá & judah, jew,  belongs, of judah            &  judá, judagua,  judápe, judágui                                                       & judá, judá suyu,  judapi, judá ayllu \\
mismo &  same, himself, own, myself              &   voi, avei, upe, pete\~{i}{i}                                                         &  kikin, kaq, chay, hina/hinalla \\
% oír & hear, heard, listen,  when                 &  {\textlangle}hendu,  kuaa, {\textlangle}hendu/ndu, japysaka                           & uyari,  uya, uyari/uyarina, uyari/uyariqkuna \\
llevar & bring,  carry, take, bear               &  raha,  {\textlangle}hupi, raha hikuái, hikuái                                         &  apa, pusa, apa/apamu, apari/apariku \\
% hecho & do,  make, done, work                    &   {\textlangle}japo, {\textlangle}japo vaekue, {\textlangle}hembiapo, mba'e            &  ruwa, ru, kama, allinta \\
dicho & say, speak,  tell, word                  &  'e,  'e/ha'e, kóicha 'e, {\textlangle}he'ika                                          & ni,  diosmi ni, apu, diosmi \\
cielo & heaven, sky,  heavens, cloud             &  yvága,  ára, yvate, yvága pe/pegua                                                    & hana/hanaq pacha,  pacha, hana/hanaq, hana/hanaq pa \\
ojo & eye, sight,  in, his eye                   &   {\textlangle}hesa, {\textlangle}hecha, ma'\~{i}{i}{e}, che                           &  ñawi, qhawari, ri/riku, ruwa \\
llegar & come,  have come, reach, when           &  guah\~{i}{i}{e},  guah\~{i}{i}{e} hikuái, ke, ja/mboja/ñemboja                        &  chaya, chaya/chayamu, hamu, cha \\
%quedar & be,  stay, remain, be leave             &   pyta, {\textlangle}hemby, {\textlangle}heja, ndopyta                                 &  kapu/kapun, kanqa, qhepaq, qhepakurqan \\
%aquel & that,  him, will, everyone               &  upe,  pe, upe upe, umiha                                                              & chay,  pipas, haqay, chaypachan \\
%% cada & each, every,  everyone, every man         &   te\~{i}{i}, opa/pa, {\textlangle}he\~{i}{i}/{\textlangle}he\~{i}{i}me/te\~{i}{i}, pete\~{i}{i} te\~{i}{i}    &  sapanka, sapa, sapa/sapan, sapankanku \\
% medio &  middle, among, through, within          &   rupi, mbytépe, apytépe, pende                                                        &  ukhu, ukhupi, chawpi, qankuna \\
entrar & enter into, come, come into, go into, go&  ke,  guah\~{i}{i}{e}, ndoike, hikuái                                                  & hayku,  hayku/haykuna, ri, hay \\
%% llamar & call, name,  whose name, summon         &  {\textlangle}héra, {\textlangle}henói,  {\textlangle}henoika/henoika, {\textlangle}henói/nói                                          &  waq/waqya, sutiyoq, waqya, suti/suticha \\
llamar & call, name, summon                      &  {\textlangle}héra, {\textlangle}henói,  {\textlangle}henoika/henoika, {\textlangle}henói/nói                                          &  waq/waqya, sutiyoq, waqya, suti/suticha \\
%espíritu & spirit,  breath, by, trouble          &  espíritu,  espíritu santo, py'a, pu'aka                                               &  santo espirituq, santo, espiritun, santo espirituqa \\
%monte & mountain, on,  mount, hill country       &  yvyty,  yvyty {\textlangle}hu'ã, ka'aguy, yvyty rupi                                  & orqo,  orqopi, orqoman, orqokuna \\
subir & go up, come up, up,  ascend              &   jupi, ha, s\~{i}{i}{e}, ju                                                           &  wicha, ri, wichari, chay/chayman \\
obra & work, do,  deed, doings                   &   {\textlangle}hembiapo, {\textlangle}japo, mba'e, mba'e {\textlangle}japo             & ruwa,  llank'a, ruwa/ruwana, ruwa/ruway \\
%% puerta & gate, door, at,  threshold              &  {\textlangle}hok\~{i}{i}{e},  k\~{i}{i}{e}, táva {\textlangle}hok\~{i}{i}{e}, {\textlangle}hok\~{i}{i}{e} nguéra          & punku,  hayku/haykuna, punku/punkuta, pun \\
% pecado & sin, iniquity, trespass,  transgression &  angaipa,  {\textlangle}hembiapo vai, vai, {\textlangle}heja rei                       & hucha, huchalli/huchalliku,  hucha/huchaku, hu \\
hija & daughter,  her, her daughter, woman       &  rajy,  kuña, memby, táva                                                              & ususi,  warmi, warmi wawa, llaq/llaqta \\
% junto & by,  together, beside, at                &   {\textlangle}hembe'y, ypýpe, ykére, \~{i}{i}                                         &  qaylla, patapi, kuska, qayllapi \\
dejar & leave,  let, allow, they                 &   {\textlangle}heja, poi, ja, jei                                                      &  kachari, ama, ma/mana, maña/mañana \\
    \hline
  \end{tabular}
  \end{centering}
  \end{tiny}
  \caption{Selected common Spanish word types with their most likely
translations. These were picked for interesting polysemy from the 100 most
common word types.}
  \label{fig:mostcommon-es-translations}
\end{figure*}

\begin{figure*}
  \begin{centering}
  \begin{tabular}{|r|c|c|c|c|}
    \hline
    rank & word type (es) & entropy (en) & entropy (gn) & entropy (qu) \\
    \hline
    1    & dios   & 3 bits  &  &  \\
    2    & pelear & 15 bits &  &  \\
    \multicolumn{5}{|c|}{...} \\ 
    500 &  & & & \\
    \hline
  \end{tabular}
  \end{centering}
  %% XXX: fill this table in
  \caption{Common Spanish word types and the entropy, in bits, faced by a
  system that must choose among the possible alternatives} 
  \label{fig:mostcommon-es-entropy}
\end{figure*}

Using larger bitexts of course will allow us to construct training and test
sets for a broader vocabulary, and with better statistical support for the
words already present. However even when working with the Bible, we
have at least fifty uses of over a thousand different lemmas, for English and
Spanish, as shown in Figure \ref{fig:mostcommon-en-es}.

%% XXX: do we want to include the stats for Europarl here too? Probably put
%% that in the monolingual and multilingual chapters.

\section{Baseline System}
At its heart, the Chipa software takes in a bitext corpus, the associated
automatic alignments, and optionally other annotations, and then, trains CL-WSD
classifiers for word types from the source language on demand. 

The software holds all of the available bitext in memory. On request, it
retrieves the relevant training sentences for the word we want to disambiguate,
finds the instances of the word and its aligned translations, and extracts
features (see Figure~\ref{fig:baselinefeatures}) from the source side to
produce the training set for that classifier.  If it has been seen aligned to
only one target-language type, then this is simply noted, and if the source
word is not present in the training data, then that word is marked
out-of-vocabulary. In these latter two cases, we skip building a classifier for
that word, since there is no ambiguity present in our examples.

Classifiers are trained with the scikit-learn machine learning toolkit
\cite{scikit-learn} for Python and its associated NLTK interface, though in
earlier versions, we used megam \cite{daume04cg-bfgs}, also through NLTK.  By
default, we use Logistic Regression classifiers (also known as Maximum
Entropy), with the default settings.  Maximum entropy classifiers are
well-suited to this sort of classification task, as they are robust to adding
large numbers of features, even highly-correlated ones \cite{nigam1999using}.
Furthermore, because we have a large number of features but a relatively small
number of samples per classifier, we train with L1 regularization rather than
L2~\cite{ng2004feature}.
We can also set a regularization parameter during training, to encourage
sparser solutions and thus avoid overfitting.  Here by default we set the
regularization parameter to $C=1.0$ ...

%% XXX: try it with a few different settings!
%% XXX also we should probably use L1 regularization, because we've got lots of
%% features and many may be irrelevant.
%% XXX: Also try some other classifier! Maybe an SVM or random forests or
%% something.

Since source-language tokens may be NULL-aligned (i.e., not all words in the
source text will have corresponding words in the target text), both in the
training data and in translations, we allow users to request classifiers that
consider NULL as a valid label for classification, or not, as appropriate for
the application. We report classification accuracies for both settings.

Memory permitting, these classifiers are kept cached for later usage. Chipa can
also be run as a server, providing an interface whereby client programs can
request CL-WSD decisions over RPC.

\begin{figure*}
  \begin{centering}
  \begin{tabular}{|r|c|}
    \hline
    name          & description  \\
    \hline
    \texttt{bagofwords}    & a feature counting each lemma in the source sentence \\
    \texttt{bagofsurface}  & like \texttt{bagofwords}, but with surface forms \\
    \texttt{window}       & a binary feature for each of the lemmas in the immediately surrounding three-word context window \\
    \texttt{surfacewindow} & like \texttt{window}, but with surface forms \\
    \hline
  \end{tabular}
  \end{centering}
  \caption{Features for the baseline Chipa system}
  \label{fig:baselinefeatures}
\end{figure*}

\section{Classification Results for the Baseline System}
%% XXX SECTIONNEEDSWORK
%% GOODUPTOHERE

\begin{itemize}
\item en-es
\item es-en
\item es-gn
\item es-qu
\end{itemize}

Words in Spanish for which we gain the most by training a classifier --
measured as the difference in accuracy between MFS 
