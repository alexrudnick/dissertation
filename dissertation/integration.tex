\chapter{Integration Into Machine Translation Systems}
\label{chap:integration}

In this chapter, we discuss how our CL-WSD techniques can be integrated into
running machine translation systems, with the goal of improving lexical
selection in practice with relatively small code changes to the MT software. We
translate from Spanish to Guarani with an off-the-shelf phrase-based
statistical MT system, and from Spanish to Quechua with a rule-based MT system
that was developed by a different research group. These two integrations are
meant to be simple proofs of concept, rather than production-ready code, but
they demonstrate at least conceptually how CL-WSD can be used with these
translation systems. Afterwards, we look at evaluating Chipa's effect on MT
output in both of these use cases.

Among other pieces of software related to this work, especially the corpus
preparation scripts, the code to integrate Chipa into these external machine
translation systems is in a software package called Tereré \footnote{Available
at \url{http://github.com/alexrudnick/terere} ; Tereré is a cold variety of
yerba mate brewed with ice water; it is a specifically Paraguayan specialty.}.

\section{Integrating Chipa into Phrase-Based Statistical Machine Translation}
Moses\footnote{Available at
\url{http://statmt.org/moses/}}\cite{koehn-EtAl:2007:PosterDemo} is a mature,
well-maintained and popular statistical machine translation package, broadly
used for both research and practical purposes. Conveniently for our work here,
it features a straightforward interface for adding feature functions to guide
the decoding process while it is constructing translations.

We built a baseline phrase-based SMT system with Moses and used this feature
function API to have Chipa evaluate candidate translations.
We also the added constraint that the source side of all phrases must be at
most one token long, to match the alignments used in the Chipa experiments.

Here the integration of Chipa is done through adding an additional feature
function to the Moses phrase-based decoder. During the search through the space
of possible translations, Moses proposes candidate translations for each source
word to Chipa, which provides a score based on how likely the translation seems
to the CL-WSD system, based on the entire source-language sentence context.
This score is returned to Moses, which combines all of the available features
in a log-linear combination.

The weights for all of the features provided to the system (translation
probabilities, LM scores, CL-WSD scores, and perhaps others) can be tuned on a
development set with MERT \cite{och:2003:ACL}; thus, if CL-WSD scores turn out
to be useful for achieving high BLEU scores on the development set sentences,
Chipa's feature function will be assigned a higher weight. If not, its advice
carries less weight, than, for example, that of the language model.


\subsection{Interfacing between Moses and Chipa}
%% write about how we can't we just annotate the phrase table for individual
%% sentences just before decoding -- we need to know about the phrase *in a
%% context* and that's the point.
We implemented a simple protocol for communication between the Moses C++ code
and the Chipa server, based on Unix pipes. In earlier work with SQUOIA
\cite{rudnick:saltmil2014}, we had communicated between Chipa and the machine
translation system with XML-RPC \footnote{\url{http://xmlrpc.scripting.com/}},
but for simplicity (and honestly, difficulties using the Moses build system),
we built a new text-based protocol.

Named Unix pipes, or FIFOs, allow the creation of a special kind of filesystem
object whereby messages can be passed between processes in the same computer.
Here Moses requests an evaluation for a certain translation of a
source-language phrase, and Chipa returns a score based on how likely it
considers that phrase.

\section{Integrating Chipa into Rule-Based Machine Translation}
SQUOIA\footnote{Code available at \url{https://github.com/a-rios/squoia};
XXX is there a good description for the project online?}
is a project for rule-based machine translation from Spanish to Quechua.

SQUOIA was developed by a team at the University of Zurich. For the most
part, it is a classical rule-based transfer system, although the team has
developed techniques for predicting verb morphology with machine
learning methods, in cases when rules cannot reliably disambiguate
\cite{riosgonzales-gohring:2013:HyTra}. It does not, by default, use machine
learning for lexical selection as such, although it does include a language
model to select among the licensed alternatives.

SQUOIA's architecture is based on the Matxin system \cite{matxin2005}, which
was originally intended for translating from Spanish to Basque.
It consists of a pipeline of smaller steps, each of which passes along a tree
describing the current input sentence, in XML form. Adding CL-WSD to this
system involves adding a step to the pipeline that interprets the XML
representation of the current sentence, constrains the lexical choices based on
the recommendations of the Chipa software, and then passes these choices to
subsequent scripts.

The core system relies on a classical transfer approach and is mostly
rule-based, with a few components based on machine learning.

Each module performs some transformation on its input and
passes along the updated version to the next stage. Many modules focus on very
particular parts of the representation, leaving most of their input unchanged.

Rios and G\"{o}hring \cite{riosgonzales-gohring:2013:HyTra} describe
earlier work on extending the SQUOIA MT system with machine learning modules.

Lexical ambiguity is a significant problem facing rule-based machine
translation systems, as many words have several possible translations in a
given target language, each of which can be considered a sense of the word from
the source language.

The difficulty of resolving these ambiguities is mitigated for 
statistical machine translation systems for language pairs with large bilingual
corpora, as large n-gram language models and phrase tables containing common
multi-word expressions can encourage coherent word choices.
For most language pairs these resources are not available, so a primarily
rule-based approach becomes attractive.

In cases where some training data is available, though, we can
investigate hybrid RBMT and machine learning approaches, leveraging small and
potentially growing bilingual corpora.

... show how it allows us to learn from the available bitext to
make better lexical choices, with very few code changes to the base system.

The integration enables SQUOIA to take advantage of any available bitext
without significantly changing its design, and to improve its word choices as
additional bitext becomes available.

In its current design, SQUOIA makes word choices based on its bilingual
lexicon; the possible translations for a given word or multi-word expression
are retrieved from a dictionary on demand. If there are several possible
translations for a lexical item, these are passed along the pipeline so
that later stages can make a decision, but if the ambiguity persists,
then the first entry retrieved from the lexicon is selected. While there are
some rules for lexical selection, they have been written by hand and only cover
a small subset of the vocabulary in a limited number of contexts.

In this work, we supplement these rules with classifiers learned from
Spanish-Quechua bitext.
These classifiers make use of regularities that may not
be obvious to human rule-writers, providing improved lexical selection for
any word type that has adequate coverage in the training corpus.

There are many dialects of Quechua; SQUOIA focuses on the
Cuzco dialect, spoken around the Peruvian city of Cuzco.

In the first stages, Spanish source sentences are analyzed with off-the-shelf
open-source NLP tools. To analyze the input Spanish text,
SQUOIA uses FreeLing \cite{padro12} for morphological analysis and named-entity
recognition,
Wapiti \cite{lavergne2010practical} for tagging,
and DeSr \cite{attardi-EtAl:2007:EMNLP-CoNLL2007} for parsing.
All of these modules rely on statistical models.

In the next step, the Spanish verbs must be disambiguated in order to assign
them a Quechua verb form for generation: a rule-based module tries to assign a
verb form to each verb chunk based on contextual information. If the rules fail to
do so due to parsing or tagging errors, the verb is marked as ambiguous and
passed on to an SVM classifier, which assigns a verb form even if the context
of that verb does not unambiguously select a target form. This is among the
most difficult parts of the
translation process, as the grammatical categories encoded in verbs differ
substantially between Spanish and Quechua. In the next step, a lexical transfer
module inserts all possible translations for every word from a bilingual dictionary.
Then a set of rules disambiguates the forms with lexical or morphological
ambiguities. However, this rule-based lexical disambiguation is very limited,
as it is not feasible to cover all possible contexts for every ambiguous word
with rules.

The rest of the system makes use of a classical transfer procedure. A following module
moves syntactic information between the nodes and the chunks in the tree, and
finally, the tree is reordered according to the basic word order in the target
language. In the last step, the Quechua surface forms are morphologically
generated through a finite state transducer.

In order to integrate Chipa into SQUOIA, we added an additional lexical
selection stage to the SQUOIA pipeline, occurring after the rule-based
disambiguation modules, but before a number of other steps. This new module
examines the XML tree structure of a SQUOIA translation in progress, and finds
nodes in the tree where there are several possible Quechua lemmas that may be
chosen as a translation. It then extracts the surface forms and lemmas of the
input sentence from the current XML tree structure, and passes these along to
the Chipa system so that we can make a prediction as to what the correct
translation for that input token should be.

For each word with such multiple translation possibilities, we look at each of
the translations under consideration by SQUOIA, and if any of them was the top 
classification output from the Chipa classifiers, we constrain SQUOIA to take
that choice.
%% XXX: working here
If there are no such overlapping translations, we
take the default entry suggested by SQUOIA's dictionary.
Notably, since Chipa and SQUOIA do not share the same lexicon and bitext alignments
may be noisy, translations
observed in the bitext may be unknown to the SQUOIA system, and lexical entries in the
SQUOIA dictionary may not be attested in the training data.

\section{Translation Evaluation for Spanish-Guarani}

%% TODO: explain how we sampled test sets, what it means that we picked verses
%% rather than sentences

%% with Chipa, tuned with MERT
%% BLEU+case.mixed+numrefs.1+smooth.exp+tok.13a+version.1.2.10 = 15.99 47.8/21.5/12.7/7.5 (BP = 0.905 ratio = 0.909 hyp_len = 3845 ref_len = 4229)

%% with Chipa features turned off, did not re-run MERT
%% BLEU+case.mixed+numrefs.1+smooth.exp+tok.13a+version.1.2.10 = 9.50 40.2/13.7/7.5/4.2 (BP = 0.830 ratio = 0.843 hyp_len = 3563 ref_len = 4229)


\section{Translation Evaluation for Spanish-Quechua}
In order to evaluate the effect of Chipa on lexical selection in a live
translation task, we used SQUOIA to translate Spanish passages for which we
had reference Quechua translations.

The first is simply a hundred verses sampled from our Spanish-Quechua Bible
bitext.


from the Bible; the second is adapted from the Peruvian government's public
advocacy website,\footnote{\emph{Defensoría del Pueblo},
\url{http://www.defensoria.gob.pe/quechua.php}} which is bilingual.
We collected and hand-aligned thirty-five sentences from this site.

%% XXX: this is probably not a good test set; we need to pick a better one.
%% Maybe also just sample some sentences from the Bible.
