\chapter{Learning from Monolingual Data}
In this chapter, we want to write about all of the things that we can do with
just monolingual data in the source language.

This is probably going to be one of the most important chapters, and really one
of the nicest results in the dissertation.

We can probably integrate some text from the SALTMIL paper into this chapter.

\section{learning with Brown Clusters}
So far, we have really good evidence that we can learn, in an unsupervised way,
with Brown Clustering (CITE: Brown et al, 1991 or so),
coarse-grained categories for word types in the source language that help us
make lexical selection distinctions.

This was done in the es-qu lexical selection task and it helped quite a lot.

There are actually several open questions here, though:

\begin{itemize}
  \item Does more source-language text help us learn ``better" Brown clusters,
    with respect to the CL-WSD task? It seems like it would, but we haven't
    demonstrated that yet.
  \item What's the relationship between the genre of the monolingual text we
    use and the source-language side of the test set? It seems to help to have
    in-domain text to train our clusters, but is there a size at which you
    learn a ``better" clustering that overtakes the in-domain-ness?
  \item We tried clustering on (lemmatized) Europarl in the es-qu experiments for SALTMIL...
  \item Does it matter if you lemmatize the Spanish first, or not? It seems
    like the point of Brown Clustering is that it's picking up on syntax in
    some sense.
\end{itemize}

\section{Maybe explain how Brown Clustering works here?}
Not sure how important this is to the argument...

\section{Other Unsupervised Word Representations}
We can try applying the other stuff in the Turian et al Word Representations
paper, and also we can try using word2vec!
