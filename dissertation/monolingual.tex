\chapter{Learning from Monolingual Data}
In this chapter, we want to write about all of the things that we can do with
just monolingual data in the source language.

This is probably going to be one of the most important chapters, and really one
of the nicest results in the dissertation.

We can probably integrate some text from the SALTMIL paper into this chapter.

\section{learning with Brown Clusters}
So far, we have really good evidence that we can learn, in an unsupervised way,
with Brown Clustering (CITE: Brown et al, 1991 or so),
coarse-grained categories for word types in the source language that help us
make lexical selection distinctions.

This was done in the es-qu lexical selection task and it helped quite a lot.

There are actually several open questions here, though:

\begin{itemize}
  \item Does more source-language text help us learn ``better" Brown clusters,
    with respect to the CL-WSD task? It seems like it would, but we haven't
    demonstrated that yet.
  \item What's the relationship between the genre of the monolingual text we
    use and the source-language side of the test set? It seems to help to have
    in-domain text to train our clusters, but is there a size at which you
    learn a ``better" clustering that overtakes the in-domain-ness?
  \item We tried clustering on (lemmatized) Europarl in the es-qu experiments for SALTMIL...
  \item Does it matter if you lemmatize the Spanish first, or not? It seems
    like the point of Brown Clustering is that it's picking up on syntax in
    some sense.
\end{itemize}

It would be good to include some nice examples of the clusters that Brown
Clustering learns, based on the different source-language corpora that we
cluster on.

\begin{figure*}[t!]
  \begin{tabular}{|l|p{12cm}|}
    \hline
    category  & top twenty word types by frequency \\
    \hline
    countries & francia irlanda alemania grecia italia españa rumanía portugal polonia suecia bulgaria austria finlandia hungría bélgica japón gran\_bretaña dinamarca luxemburgo bosnia \\
    \hline
    more places & kosovo internet bruselas áfrica iraq lisboa chipre afganistán estrasburgo oriente\_próximo copenhague asia chechenia gaza oriente\_medio birmania londres irlanda\_del\_norte berlín barcelona \\
    \hline
    mostly people & hombre periodista jefes\_de\_estado individuo profesor soldado abogado delincuente demócrata dictador iglesia alumno adolescente perro chico economista gato jurista caballero bebé \\
    \hline
    infrastructure & infraestructura vehículo buque servicio\_público cultivo edificio barco negocio motor avión monopolio planta ruta coche libro aparato tren billete actividad\_económica camión \\
    \hline
    common verbs & pagar comprar vender explotar practicar soportar exportar comer consumir suministrar sacrificar fabricar gobernar comercializar cultivar fumar capturar almacenar curar beber \\
    \hline
  \end{tabular}
\caption{Some illustrative clusters found by the Brown clustering algorithm on
the lemmatized version of the Spanish Europarl corpus. These are five out of
the $C=1000$ clusters, picked and labeled arbitrarily. The
words listed are the top twenty terms from that cluster, by frequency.}
\label{fig:clusters}
\end{figure*}

\section{Maybe explain how Brown Clustering works here?}
Not sure how important this is to the argument...

\section{Other Unsupervised Word Representations}
We can try applying the other stuff in the Turian et al Word Representations
paper, and also we can try using word2vec!
