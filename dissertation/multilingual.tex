\chapter{Learning from Multilingual Data}
\label{chap:multilingual}

As discussed in previous chapters, while our target languages are
under-resourced, we have many resources available for our source languages.
Concretely for Spanish, in addition to the abundant monolingual text and
off-the-shelf NLP tools, as discussed in Chapter \ref{chap:monolingual}, we
have a significant amount of bitext, pairing Spanish with languages other than
our under-resourced target languages. We would like to be able to learn from
these other bitext corpora when translating from Spanish to Guarani and
Quechua, and ideally in general from resource-rich source languages into
under-resourced target languages.

Each bitext corpus may contain useful examples of a given source language word,
and senses of that word may be lexicalized differently in the various target
languages, giving us clues about the meaning of each token in its context.
Selecting a contextually correct translation for source-language words is
evidence that we have understood the meaning of those words, at least
implicitly, in as far as sense distinctions are surfaced in the target
language. So we would like our system to be able to learn relationships between
the senses of a given source word, as they are represented in different target
languages. Two target languages may happen to surface similar sense
distinctions, perhaps due to being related languages, or perhaps because a word
sense ambiguity is unusual in the source language, or simply by coincidence.
Additionally, a combination of translations into several languages may provide
evidence for a certain lexical choice in the target language of interest.

In this chapter, we present strategies for learning from the available bitext
corpora that do not include our under-resourced target languages, to help us
make better CL-WSD decisions when translating into them. Primarily we discuss a
``classifier stacking" approach, in which we train CL-WSD classifiers
translating from Spanish to other European languages, and use the outputs of
these classifiers as features for Spanish to Quechua and Spanish to Guarani.

The approaches in this chapter are particularly informed by the work of Els
Lefever \emph{et. al} (see especially
\cite{lefever-hoste-decock:2011:ACL-HLT2011}), in which entire source sentences
are machine-translated into several different target languages just before
feature extraction, and these entire sentences are used to produce signals for
CL-WSD classifiers. One drawback of this technique is that it could be
considered unwieldy from a software engineering perspective; it requires
multiple complete MT systems to perform CL-WSD, which is rather complex when we
want to use CL-WSD as a subcomponent of a machine translation system in the
first place.

In earlier work, considering the work of Lefever \emph{et. al}, we developed
some prototype CL-WSD systems that made use of multilingual evidence
\cite{rudnick-liu-gasser:2013:SemEval-2013} and produced some of the top
results in a SemEval shared task on CL-WSD \cite{task10}.
Here our systems trained with multilingual evidence posted better performance
than the one that used monolingual features; our top results in every language
came from either classifier stacking or the Markov network classifier. This
suggests that it is possible to use evidence in several parallel corpora for
CL-WSD without translating source sentences into many target languages.

In this SemEval paper, we presented two different approaches for making use of
multilingual evidence. The more complex of them was a system based on graphical
models that performed loopy belief propagation over Markov networks, which we
will discuss briefly in Section~\ref{sec:multilingual-mrf}. The simpler
approach described in that work was a relatively straightforward classifier
stacking approach, where the outputs of several CL-WSD classifiers were used as
input features for one final classifier. This approach is more immediately
applicable to lexical selection when our target language is under-resourced, as
it does not require bitext corpora between all of the involved languages.

\section{Multilingual evidence from the Europarl corpus} 
There are quite a few bitext resources available for many European languages,
especially the official languages of the European Union.
Through the Europarl corpus \cite{europarl}, for example, we have bitext
corpora in which Spanish is paired with English, German, French, and 17 other
European languages.

%% XXX what else to say about Europarl?

\section{Multilingual evidence from Bible translations}
%% XXX we're also going to have to write about training on the bibles here.

\section{CL-WSD with Markov Networks}
\label{sec:multilingual-mrf}
In our SemEval entry \cite{rudnick-liu-gasser:2013:SemEval-2013}, we
investigated a CL-WSD approach based on Markov networks (also known as ``Markov
Random Fields"), building a network of interacting variables (see Figure
\ref{fig:pentagram}) to solve CL-WSD classification problems for the five
target languages of the SemEval 2013 task \cite{task10}. In this task, we were
given English source sentences with an annotated focus word (from a given set
of possible focus words types), and asked to make correct lexical selections
for translating into Dutch, French, German, Italian and Spanish. The ground
truth for the task was determined by human annotators familiar with those
languages.

Here the nodes in our Markov network represent random variables that take on
values corresponding to the possible translations for each of the five target
languages. The probability distributions over these translations are produced
by language-specific maximum entropy classifiers, effectively applying the
baseline Chipa system on the given input sentence.

The edges in the graph correspond to pairwise potentials that are derived from
the joint probabilities of target language labels co-occurring in the available
bitext for the two target languages along that edge of the graph. This approach
thus requires a bitext corpus for each pair of languages in the set of
languages involved; for the SemEval task, we worked with a subset of the
Europarl corpus, provided by the task organizers, in which every sentence was
provided for all six languages.

We frame the task of finding the optimal translations into five languages
jointly as a MAP inference problem, wherein we try to maximize the joint
probability of all five variables, given the single source language sentence.
We perform inference with loopy belief propagation
\cite{DBLP:conf/uai/MurphyWJ99}, which is an approximate but tractable
inference algorithm that, while giving no guarantees, often produces good
solutions in practice.
We used the formulation for pairwise Markov networks that passes messages
directly between the nodes rather than first constructing a ``cluster graph",
which is described in \cite[\S 11.3.5.1]{Koller+Friedman:09} of Koller and
Friedman's book on graphical models. This Markov network approach has the
theoretically satisfying property that it takes seriously the uncertainty
present in the predictions of each of the component classifiers and solves the
entire problem jointly. 

Intuitively, at each time step loopy belief propagation passes messages around
the graph that inform each neighbor about the estimate, from the perspective of
the sender and what it has heard from its other neighbors, of the minimum
penalty that would be incurred if the recipient node were to take a given
label. As a concrete example, when the \emph{nl} node sends a message to the
\emph{fr} node at time step 10, this message is a table mapping from all
possible French translations of the current target word to their associated
penalty values. The message depends on three things: the probability
distribution from a monolingual classifier just for Dutch, joint probabilities
estimated from our Dutch-French bitext, and the messages from the \emph{es},
\emph{it} and \emph{de} nodes from time step 9.

\begin{figure}
  \begin{center}
  \includegraphics[width=5cm]{pentagram.pdf}
  \end{center}
  \caption{The network structure used in the MRF system for SemEval: a complete
  graph with five nodes, in which each node represents the random variable for
  the translation into a target language.}
  \label{fig:pentagram}
\end{figure}

%% XXX: this needs a better explanation; we can't help the gn classifier with
%% the MRF in this graph.
\begin{figure}
  \begin{center}
  \includegraphics[width=5cm]{gn-qu-mrf.pdf}
  \end{center}
  \caption{Hypothetical network structure -- not fully connected -- that could
  be used for a Markov network, if we had a bitext corpus for Spanish and every
  other language, for German-English, and for German-Quechua. Here we draw a
  shaded node for Spanish, representing the bitext between the source language
  and each of the }
  \label{fig:gn-qu-mrf}
\end{figure}

While we were able to achieve fairly good results with these MRF-based
classifiers on the Semeval CL-WSD task, our strategy for setting the weights in
the Markov network requires, for each edge in the graph, a parallel corpus for
the corresponding language pair. The bitext for each language pair need not be
mutually parallel among all of the languages present; each edge in the graph
may correspond to an unrelated bitext corpus.  Also, in principle the graph
need not be fully connected, as it was for our SemEval entry, but this approach
does require bitext between the source language, our target language of
interest, and at least one of the other language; see
Figure~\ref{fig:gn-qu-mrf} for a hypothetical network structure that could be
used, given the right bitext.

Considering the limited bitext resources available, this approach is less
easily applicable for the under-resourced target language use case.  In the
classifier stacking approach, it is clear how we can include information from
many heterogeneous sources. The Markov network approach may be useful for
future CL-WSD systems in other settings, but we will not make further use of it
for translating into under-resourced languages, since we do not have many
parallel corpora available for Guarani or Quechua.

\section{Classifier stacking}
The classifier stacking approach, in order to predict the translation of a word
into a given target language, uses translations into other available target
languages as features.
For example, for our SemEval prototype systems, in order to translate an
English word into Spanish, we predict that word's translations into French,
Italian, Dutch and German, and then encode those predicted translations as
features for our English to Spanish classifier.

%% XXX this needs some editing

We would like to try adding classifiers trained on the other Europarl
languages, as well as completely different corpora; this would require that for
the stacked classifier, we would train on predicted translations rather than...

This approach only requires that the monolingual classifiers make \emph{some}
prediction based on text in the source language; they need not be trained from
the same source text, depend on the same features, or even output words as
labels.

\subsection{Classifier stacking in practice}
Here we train the baseline Chipa system, with the baseline feature set, on both
Europarl bitext pairing Spanish with each of five other languages, and on
verse-aligned Bible translations. Following
earlier work, including our system for SemEval and that of Lefever \emph{et
al.}, the target languages used are Dutch, English, French, German, and
Italian.

The bitext corpora are prepared with the tools distributed with the Europarl
corpus; once we have sentence-aligned bitext, we preprocess the bitext in a
similar way to the Bible text, as described in
Section~\label{sec:datasetsandpreprocessing}. Where possible, we lemmatize the
target-language text with FreeLing. However, as of this writing FreeLing does
not support Dutch, so for Dutch, we use the Frog text analysis
tool\footnote{Frog was developed by groups at Tilburg
University and the University of Antwerp. It is available at
\url{http://languagemachines.github.io/frog/}} \cite{tadpole2007}. With the
exception of the different lemmatizer for Dutch, the preprocessing steps are
analogous to those described in the previous chapters, resulting in
automatically aligned Spanish-Dutch, Spanish-English, Spanish-French,
Spanish-German, and Spanish-Italian bitext corpora.

\section{Domain mismatches}

\section{Experiments}
\label{sec:multilingual-experiments}
... same as before, right?

\section{Experimental Results}
\label{sec:multilingual-results}

\subsection{Results: classifier stacking with Europarl}

\begin{figure*}
  \begin{centering}
  \begin{tabulary}{\textwidth}{|R|L|L|L|L|}
    \hline
    classifier & es-gn regular & es-gn non-null & es-qu regular & es-qu non-null \\

    \hline
    MFS    & 0.456 & 0.498 & 0.435 & 0.391 \\
    \hline
    \hline

    \multicolumn{5}{|l|}{maxent l1} \\
    \hline
    baseline features & 0.461 & 0.506 & 0.444 & 0.414 \\
    \hline
    +all syntactic features & 0.465 & 0.511 & 0.450 & 0.422 \\
    \hline
europarl stacking, en only & 0.461 & 0.506 & 0.444 & 0.414 \\
    \hline
europarl stacking, en only +syntactic & 0.465 & 0.511 & 0.450 & 0.422 \\
    \hline
europarl stacking, 5 languages & 0.460 & 0.505 & 0.444 & 0.414 \\
    \hline
europarl stacking, 5 languages +syntactic & 0.464 & 0.510 & 0.449 & 0.422 \\
    \hline
    \hline

    \multicolumn{5}{|l|}{maxent l2} \\
    \hline
    baseline features & 0.475 & 0.524 & 0.458 & 0.431 \\
    \hline
    +all syntactic features & 0.480 & 0.530 & 0.465 & 0.441 \\
    \hline
europarl stacking, en only & 0.476 & 0.525 & 0.458 & 0.433 \\
    \hline
europarl stacking, en only +syntactic & 0.481 & 0.530 & 0.466 & 0.442 \\
    \hline
europarl stacking, 5 languages & 0.477 & 0.526 & 0.461 & 0.435 \\
    \hline
europarl stacking, 5 languages +syntactic & 0.482 & 0.531 & 0.467 & 0.444 \\
    \hline
    \hline

    \multicolumn{5}{|l|}{random forest} \\
    \hline
    baseline features & 0.481 & 0.520 & 0.464 & 0.424 \\
    \hline
    +all syntactic features & 0.486 & 0.527 & 0.471 & 0.434 \\
    \hline
europarl stacking, en only & 0.482 & 0.522 & 0.464 & 0.425 \\
    \hline
europarl stacking, en only +syntactic & 0.486 & 0.527 & 0.472 & 0.436 \\
    \hline
europarl stacking, 5 languages & 0.483 & 0.523 & 0.466 & 0.428 \\
    \hline
europarl stacking, 5 languages +syntactic & 0.487 & 0.527 & 0.473 & 0.438 \\
    \hline
  \end{tabulary}
  \end{centering}
  \caption{Results for stacking with Europarl.}
  \label{fig:europarl-stacking-results}
\end{figure*}

\subsection{Results: classifier stacking with Bibles}
\begin{figure*}
  \begin{centering}
  \begin{tabulary}{\textwidth}{|R|L|L|L|L|}
    \hline
    classifier & es-gn regular & es-gn non-null & es-qu regular & es-qu non-null \\

    \hline
    MFS    & 0.456 & 0.498 & 0.435 & 0.391 \\
    \hline
    \hline

    \multicolumn{5}{|l|}{maxent l1} \\
    \hline
    baseline features & 0.461 & 0.506 & 0.444 & 0.414 \\
    \hline
    +all syntactic features & 0.465 & 0.511 & 0.450 & 0.422 \\
    \hline
bible stacking, en only & 0.463 & 0.508 & 0.446 & 0.416 \\
    \hline
bible stacking, en only +syntactic & 0.466 & 0.513 & 0.451 & 0.425 \\
    \hline
bible stacking, 5 languages & 0.466 & 0.512 & 0.449 & 0.419 \\
    \hline
bible stacking, 5 languages +syntactic & 0.469 & 0.516 & 0.453 & 0.427 \\
    \hline
    \hline

    \multicolumn{5}{|l|}{maxent l2} \\
    \hline
    baseline features & 0.475 & 0.524 & 0.458 & 0.431 \\
    \hline
    +all syntactic features & 0.480 & 0.530 & 0.465 & 0.441 \\
    \hline
bible stacking, en only & 0.478 & 0.527 & 0.461 & 0.435 \\
    \hline
bible stacking, en only +syntactic & 0.482 & 0.532 & 0.467 & 0.444 \\
    \hline
bible stacking, 5 languages & 0.484 & 0.533 & 0.468 & 0.443 \\
    \hline
bible stacking, 5 languages +syntactic & 0.487 & 0.538 & 0.472 & 0.450 \\
    \hline

    \multicolumn{5}{|l|}{random forest} \\
    \hline
    baseline features & 0.481 & 0.520 & 0.464 & 0.424 \\
    \hline
    +all syntactic features & 0.486 & 0.527 & 0.471 & 0.434 \\
    \hline
bible stacking, en only & 0.484 & 0.525 & 0.466 & 0.428 \\
    \hline
bible stacking, en only +syntactic & 0.488 & 0.529 & 0.473 & 0.439 \\
    \hline
bible stacking, 5 languages & 0.488 & 0.530 & 0.470 & 0.434 \\
    \hline
bible stacking, 5 languages +syntactic & 0.492 & 0.533 & 0.476 & 0.441 \\
    \hline
  \end{tabulary}
  \end{centering}
  \caption{Results for stacking with Bibles.}
  \label{fig:bible-stacking-results}
\end{figure*}

\section{Discussion}

