\chapter{Learning from Multilingual Data}
\label{chap:multilingual}
As discussed in previous chapters, while our target languages are
under-resourced, we have many resources available for our source languages.
Concretely for Spanish, in addition to the abundant monolingual text and
off-the-shelf NLP tools, as discussed in Chapter \ref{chap:monolingual}, we
have a significant amount of bitext, pairing Spanish with languages other than
our under-resourced target languages. We would like to be able to learn from
these available bitext corpora when translating from Spanish to Guarani and
Quechua, and ideally in general from resource-rich source languages into
under-resourced target languages.

Each bitext corpus may contain useful examples of a given source language word,
and senses of that word may be lexicalized in distinct ways in different target
languages, giving us clues about the meaning of each token in its context.
Selecting a contextually correct translation for source-language words is
evidence that we have understood the meaning of those words, at least
implicitly, in as far as sense distinctions are surfaced in the target
language. So we would like our system to be able to learn relationships between
the senses of a given source word as they are represented in different target
languages. Two target languages may happen to surface similar sense
distinctions, perhaps due to being related languages, or perhaps because a word
sense ambiguity is unusual in the source language, or simply by coincidence.
Additionally, a combination of translations into several languages may provide
evidence for a certain lexical choice in the target language of interest.

In this chapter, we present strategies for learning from the available bitext
corpora that do not include our under-resourced target languages, to help us
make better CL-WSD decisions when translating into them. To establish
consistent terminology, we will call these \emph{supplemental} bitext corpora.
Primarily we discuss a ``classifier stacking" approach, in which we train
``supplemental" CL-WSD classifiers translating from Spanish to other European
languages, based on our supplemental corpora, and use the outputs of these
classifiers as features for Spanish to Quechua and Spanish to Guarani.

The approaches in this chapter are particularly informed by the work of Els
Lefever \emph{et. al} (see especially
\cite{lefever-hoste-decock:2011:ACL-HLT2011}), in which entire source sentences
are machine-translated into several different target languages just before
feature extraction, and these translated sentences are used to produce features
for CL-WSD classifiers. One drawback of this technique is that it could be
considered unwieldy from a software engineering perspective; it requires
multiple complete MT systems to perform CL-WSD, when we want to use CL-WSD as a
subcomponent of a machine translation system in the first place.

In earlier work, considering the work of Lefever \emph{et. al}, we developed
prototype CL-WSD systems that made use of multilingual evidence
\cite{rudnick-liu-gasser:2013:SemEval-2013} and produced some of the top
results in a SemEval shared task on CL-WSD \cite{task10}.
Our systems trained with multilingual evidence posted better performance than
the one that used monolingual features; our top results in every language came
from either classifier stacking or a classifier based on Markov networks,
an approach which we will discuss briefly in
Section~\ref{sec:multilingual-mrf}. This suggests that it is possible to use
evidence in several parallel corpora for CL-WSD without translating input
sentences into many target languages.

For the rest of the chapter, we will describe some of the supplemental bitext
corpora that we can use for CL-WSD from Spanish, the Markov network approach
described in our SemEval entry, and the classifier stacking approach. Then we
present experiments and experimental results using classifier stacking for
Spanish-Guarani and Spanish-Quechua CL-WSD tasks.

\section{Supplemental multilingual corpora} 

Following our earlier work, and that of Lefever \emph{et. al}, we limit the
scope of our supplemental corpora to adding five additional languages; there is
an enormous combinatorial potential for running experiments with different
subsets of the available languages; in the interest of not only constraining
the search space, but also not fishing for impressive-seeming results when we
only have a small amount of bitext for the language pairs directly addressed in
this work, we will only make use of Spanish to Dutch, English, French, German,
and Italian. Experimenting with more language pairs, or different language
pairs, may be effective or appropriate in other settings, but we consider it
outside the scope of the current effort.

\subsection{Europarl}
There are several freely available bitext resources for many European
languages, especially the official languages of the European Union. Through the
Europarl corpus \cite{europarl}, for example, we have bitext corpora in which
Spanish is paired with English, German, French, and 17 other European
languages. This corpus is derived from the human-translated proceedings of
European Parliament, and so its subject matter pertains to parliamentary
procedure and discussions pertinent to modern-day European policy issues; while
it provides a substantial sample of bitext, it does not at first glance seem
particularly similar to our Bible bitext for Spanish-Guarani and
Spanish-Quechua. We will investigate the differences in text domain further in
Section~\ref{sec:domainmismatches}, but whether this text is helpful in
practice is an empirical question.

Using the automatic tools distributed with the corpus\footnote{Available
online at \url{http://statmt.org/europarl/}}, we produced sentence-aligned
and tokenized bitext, ending up with roughly 1.7 sentence pairs per language
pair, though this number varies somewhat.
We then preprocess the extracted bitext with the same steps used on our Bible
text, as described in Section~\label{sec:datasetsandpreprocessing}. Where
possible, we lemmatize the target-language text with FreeLing. However, as of
this writing FreeLing does not support Dutch, so for Dutch, we use the Frog
text analysis tool\footnote{Frog was developed by groups at Tilburg University
and the University of Antwerp. It is available at
\url{http://languagemachines.github.io/frog/}} \cite{tadpole2007} for
lemmatization. With the exception of the different lemmatizer for Dutch, the
preprocessing steps are the same as those described in the previous chapters,
resulting in automatically aligned Spanish-Dutch, Spanish-English,
Spanish-French, Spanish-German, and Spanish-Italian bitext corpora for our
experiments.

\subsection{Bible translations}

For the additional European languages, Bible translations were made available
as part of a project by Christodouloupoulos \emph{et
al.}\cite{Christodouloupoulos2015}\footnote{Their provided Bible text is
available online at \url{https://github.com/christos-c/bible-corpus}}. It is
fortunate that these translations are freely available online; as discussed
previously in Section~\label{sec:datasetsandpreprocessing}, not all languages
have publicly redistributable full-text Bibles available. As an additional
convenience, the Bible translations provided by Christodouloupoulos \emph{et
al.} come in a standardized XML-based format\footnote{Appropriately called the
Corpus Encoding Standard, described at \url{https://www.cs.vassar.edu/CES/}}.

\section{Considering domain mismatches}
\label{sec:domainmismatches}
In comparing the use of different corpora for our classifier stacking approach,
we want investigate to what extent the domain mismatch will play a role.
The subjects discussed in European Parliament may not match that of our
Spanish-Guarani and Spanish-Quechua Bible corpora; furthermore, perhaps the
word types used in the text may not match at all. This issue is especially
relevant for the techniques described in this chapter; if we do not have any
examples of a given word type in our supplemental bitext, then we cannot train
supplemental classifiers to help us with our main classification task.

Comparing our bitext corpora, we find that, indeed, many of the word types used
in our Spanish Bible translation either never appear, or only appear very
rarely in the Europarl text. However, while there are many word types that are
commonly used in the Bible text that never appear in our Europarl corpus, these
make up a small fraction of the tokens of the Bible text overall, and thus a
small number of the CL-WSD problem instances in our experiments.

Here we focus on word types that appear at least fifty times in the Bible
bitext and are thus included in our set of CL-WSD classification instances,
per the standard established in Chapter~\ref{chap:evaluation}.
Comparing, for example, our Spanish-German Europarl text with our
Spanish-Guarani Bible corpus, 24\% of the focus word types for which we want to
build classifiers appear fewer than fifty times in the Europarl corpus. 13\%
appear fewer than ten times, and 6\% of the word types never appear at all.

Out of the word types that appear in our Bible bitext but never in the Europarl
bitext, the majority are either names for people (\emph{e.g.}, \emph{Zacarías},
\emph{Nabucodonosor}, \emph{Balaam}) or Biblical locations (\emph{Galilea},
\emph{Galaad}). Other common themes are colocations referring to God (these are
joined into a single token during preprocessing; \emph{e.g.},
\emph{Cristo\_Jesús}, \emph{Señor\_Jesucristo} and \emph{Dios\_de\_Israel}. We
also see concepts that are simply not often discussed in European Parliament,
such as \emph{fornicación} ('fornication'), \emph{ungir} ('to anoint'),
\emph{heredad} ('inheritance'), and \emph{querubín} ('cherub')\footnote{Those
familiar with the English word ``cherub" and its Hebrew-style plural
``cherubim" might expect that the Spanish \emph{querubín} would be plural.
However, this word refers to a singular angel, and the plural of
\emph{querubín} is \emph{querubines}.}.

However, turning our focus to tokens, rather than word types, our annotation
process based on the Europarl bitext is able to come up with some prediction
for about 96.4\% of the Spanish-Guarani CL-WSD problems, so the absence of
these particular word types, should not, on its own, prevent the Europarl
corpus from providing useful signal for the great majority of our CL-WSD
problems.

%% this many appear >= 50: 714 / 934 = 0.76
%% this many appear >= 10: 815 / 934 = 0.87
%% this many never appear: 58 / 934 = 0.062

%% output for running compare_stacking on the es-gn training data
%% this many total instances 228698
%% this many with bible 228610
%% this many with europarl 220613


\section{CL-WSD with Markov Networks}
\label{sec:multilingual-mrf}
In our SemEval entry \cite{rudnick-liu-gasser:2013:SemEval-2013}, we
investigated a CL-WSD approach based on Markov networks (also known as ``Markov
Random Fields"), building a network of interacting variables (see Figure
\ref{fig:pentagram}) to solve CL-WSD classification problems for the five
target languages of the SemEval 2013 task \cite{task10}. In this task, we were
given English source sentences with an annotated focus word (from a given set
of possible focus words types), and asked to make correct lexical selections
for translating into Dutch, French, German, Italian and Spanish. The ground
truth for the task was determined by human annotators familiar with those
languages.

Here the nodes in our Markov network represent random variables that take on
values corresponding to the possible translations for each of the five target
languages. The probability distributions over these translations are produced
by language-specific maximum entropy classifiers, effectively applying the
baseline Chipa system on the given input sentence.

The edges in the graph correspond to pairwise potentials that are derived from
the joint probabilities of target language labels co-occurring in the available
bitext for the two target languages along that edge of the graph. This approach
thus requires a bitext corpus for each pair of languages in the set of
languages involved; for the SemEval task, we worked with a subset of the
Europarl corpus, provided by the task organizers, in which every sentence was
provided for all six languages.

We frame the task of finding the optimal translations into five languages
jointly as a MAP inference problem, wherein we try to maximize the joint
probability of all five variables, given the single source language sentence.
We perform inference with loopy belief propagation
\cite{DBLP:conf/uai/MurphyWJ99}, which is an approximate but tractable
inference algorithm that, while giving no guarantees, often produces good
solutions in practice.
We used the formulation for pairwise Markov networks that passes messages
directly between the nodes rather than first constructing a ``cluster graph",
which is described in \cite[\S 11.3.5.1]{Koller+Friedman:09} of Koller and
Friedman's book on graphical models. This Markov network approach has the
theoretically satisfying property that it takes seriously the uncertainty
present in the predictions of each of the component classifiers and solves the
entire problem jointly. 

Intuitively, at each time step loopy belief propagation passes messages around
the graph that inform each neighbor about the estimate, from the perspective of
the sender and what it has heard from its other neighbors, of the minimum
penalty that would be incurred if the recipient node were to take a given
label. As a concrete example, when the \emph{nl} node sends a message to the
\emph{fr} node at time step 10, this message is a table mapping from all
possible French translations of the current target word to their associated
penalty values. The message depends on three things: the probability
distribution from a monolingual classifier just for Dutch, joint probabilities
estimated from our Dutch-French bitext, and the messages from the \emph{es},
\emph{it} and \emph{de} nodes from time step 9.

\begin{figure}
  \begin{center}
  \includegraphics[width=5cm]{pentagram.pdf}
  \end{center}
  \caption{The network structure used in the MRF system for SemEval: a complete
  graph with five nodes, in which each node represents the random variable for
  the translation into a target language.}
  \label{fig:pentagram}
\end{figure}

\begin{figure}
  \begin{center}
  \includegraphics[width=5cm]{gn-qu-mrf.pdf}
  \end{center}
  \caption{Hypothetical network structure -- not fully connected -- that could
  be used for a Markov network translating from Spanish to all of the six
  languages shown, if we had a bitext corpus for Spanish and every
  other language, for also for German-Quechua.}
  \label{fig:gn-qu-mrf}
\end{figure}

While we were able to achieve fairly good results with these MRF-based
classifiers on the Semeval CL-WSD task, our strategy for setting the weights in
the Markov network requires, for each edge in the graph, a parallel corpus for
the corresponding language pair. The bitext for each language pair need not be
mutually parallel among all of the languages present; each edge in the graph
may correspond to an unrelated bitext corpus.  Also, in principle the graph
need not be fully connected, as it was for our SemEval entry; see
Figure~\ref{fig:gn-qu-mrf} for a hypothetical graph structure that could be
used with the right bitext corpora available. But this approach
does require bitext between the source language and all other languages
involved, as well as our target language of interest and at least one of the
other language, so that our choices for that other language can inform our
choices for the target language of interest.

Considering the limited bitext resources available, this approach is less
easily applicable for the under-resourced target language use case; concretely,
we do not have Europarl corpora available for Quechua and Guarani. In the
classifier stacking approach, it is clear how we can include information from
many heterogeneous sources. The Markov network approach may be useful for
future CL-WSD systems in other settings, but for now we will not make further
use of it for translating into under-resourced languages, since we do not have
many parallel corpora available for Guarani or Quechua.

\section{Classifier stacking}

The simpler approach that we use in practice in this work in a form of
classifier stacking. In order to predict the translation of a word into our
intended target language, we use features based on our predictions for
translations of tokens in the current sentence into \emph{other} available
target languages.
For example, in our SemEval prototype systems, in order to translate an
English word into Spanish, we predict that word's translations into French,
Italian, Dutch and German, and then encode those predicted translations as
features for our English to Spanish classifier.

This approach only requires that the classifiers used for generating new
features make \emph{some} prediction based on the input text. These classifiers 
need not be trained from the same source text, or depend on the same features,
or even necessarily output words as features. Similar to our use of syntactic
NLP tools in the previous chapter, we could use any annotation on the text for
extracting features, if we expect it will provide a meaningful clue about the
meaning of the input. For example, we could use this technique with a
monolingual WSD system that output word sense annotations and extract features
from these sense labels.

As a concrete example, say we are trying to translate a Spanish sentence to
English, and we would like to make a lexical selection for the word
\emph{estación}, which can translate to English as either ``station" (like a
train station) or ``season".

\enumsentence{
Mi \emph{estación} favorita es la primavera. }
\label{sent:estacion}

If we had a Spanish to French CL-WSD system, and this system returned
\emph{saison} (rather than \emph{gare}, the French word for a train station)
for this instance of \emph{estación}, we would expect that this would be a very
useful signal for our Spanish to English classifier.

\subsection{Annotating the bitext with stacking predictions}

Here we train the baseline Chipa system with the default feature set described
in Chapter~\ref{chap:baseline}, on both Europarl bitext and on verse-aligned
Bible translations, for the same five European target languages. For all of
the stacking classifiers mapping from Spanish to another European language, we
used a random forest classifier and the ``regular" setting. So as a result, we
came up with ten different sets of stacking classifiers, the first five of
which were trained with Europarl data, and the latter five with Bible data.

We then annotate our bitext for Spanish-Guarani and Spanish-Quechua, finding
each instance of the in-vocabulary focus words for that language pair (see
Section \ref{sec:exploring}) and classifying that instance with each of the
trained CL-WSD classifiers. The prediction for each instance, for each
classifier, is recorded as an annotation on that token (see Section
\ref{sec:annotations}), for use in later feature extraction. If no prediction
was made for a given token, either because a word is not in our list of focus
words for the given language pair, or because there were too few instances of
that word in the supplemental bitext, then no annotation is recorded.

\section{Experiments}
\label{sec:multilingual-experiments}

The experiments in this chapter are analogous to the ones in previous chapters,
with the addition of features based on classifier stacking. We ran the same
machine learning algorithms on the same training and test sentences as in
previous chapters, for both Spanish-Guarani and Spanish-Quechua.

For all tasks in this section, we trained with the baseline features described
in Chapter~\ref{chap:baseline}, as well as the new features introduced in this
chapter; these are presented in Figure~\ref{fig:stackingfeatures}.  We also
trained classifiers with the addition of the syntactic features described in
Chapter~\ref{chap:monolingual}. Classifier stacking experiments were done with
both ``English only" variants, in which the only additional features added were
based on the Spanish-English classifier, and the ``five languages" variant,
where we added features based on the predictions for Spanish to Dutch, English,
French German and Italian. The predictions provided were based on classifiers
trained on Europarl, on the Bible, and then both classifiers together; this
last approach added two separate sets of stacking features to the classifiers.
In addition to simply including the predictions for the current focus word as
features, we also include features based on predictions that we were able to
make for any tokens in a context window three tokens on either side of the
current focus word.

\begin{figure*}
  \begin{centering}
  \begin{tabular}{|p{3.5cm}|p{11cm}|}
    \hline
    name          & description  \\
    \hline
    \texttt{stacking\_en} & Predicted translation of the current token into
    English, if one was available. Feature is not present if no prediction was
    made for this token. \\
    \hline
    \texttt{stacking\_de}, \texttt{stacking\_fr}, \texttt{stacking\_it},
    \texttt{stacking\_nl} & as before, but with a prediction into the
    corresponding language.\\
    \hline
    \texttt{stacking\_window} & The predictions for any tokens in the
    surrounding context window, into any of the available languages for this
    run. \\
    \hline
  \end{tabular}
  \end{centering}
  \caption{Classifier features based on classifier stacking, used in these
  experiments}
  \label{fig:stackingfeatures}
\end{figure*}

\section{Experimental Results}
\label{sec:multilingual-results}

This section contains several tables of numbers; as before, for each set of
experimental results presented, the top result for each setting is presented in
\emph{italics}, and the top result for a setting presented in the whole
chapter, or a result tied for the top result, is presented in \textbf{bold}.

\subsection{Results: classifier stacking with Europarl}

In Figure \ref{fig:europarl-stacking-results}, we present results for the
experiments with stacking using the Europarl bitext. We see a performance
improvement here for the L2-norm maximum entropy and random forest classifiers;
for both language pairs and both settings, we see an improvement of two to four
tenths of a percentage point when using all five Europarl languages, and a
smaller benefit from using Spanish-English only.

\begin{figure*}
  \begin{centering}
  \begin{tabulary}{\textwidth}{|R|L|L|L|L|}
    \hline
    classifier & es-gn regular & es-gn non-null & es-qu regular & es-qu non-null \\

    \hline
    MFS    & 0.456 & 0.498 & 0.435 & 0.391 \\
    \hline
    \hline

    \multicolumn{5}{|l|}{maxent l1} \\
    \hline
    baseline features & 0.461 & 0.506 & 0.444 & 0.414 \\
    \hline
    +all syntactic features & 0.465 & 0.511 & 0.450 & 0.422 \\
    \hline
europarl stacking, en only & 0.461 & 0.506 & 0.444 & 0.414 \\
    \hline
europarl stacking, en only +syntactic & 0.465 & 0.511 & 0.450 & 0.422 \\
    \hline
europarl stacking, 5 languages & 0.460 & 0.505 & 0.444 & 0.414 \\
    \hline
europarl stacking, 5 languages +syntactic & 0.464 & 0.510 & 0.449 & 0.422 \\
    \hline
    \hline

    \multicolumn{5}{|l|}{maxent l2} \\
    \hline
    baseline features & 0.475 & 0.524 & 0.458 & 0.431 \\
    \hline
    +all syntactic features & 0.480 & 0.530 & 0.465 & 0.441 \\
    \hline
europarl stacking, en only & 0.476 & 0.525 & 0.458 & 0.433 \\
    \hline
europarl stacking, en only +syntactic & 0.481 & 0.530 & 0.466 & 0.442 \\
    \hline
europarl stacking, 5 languages & 0.477 & 0.526 & 0.461 & 0.435 \\
    \hline
europarl stacking, 5 languages +syntactic & 0.482 & \emph{0.531} & 0.467 & \emph{0.444} \\
    \hline
    \hline

    \multicolumn{5}{|l|}{random forest} \\
    \hline
    baseline features & 0.481 & 0.520 & 0.464 & 0.424 \\
    \hline
    +all syntactic features & 0.486 & 0.527 & 0.471 & 0.434 \\
    \hline
europarl stacking, en only & 0.482 & 0.522 & 0.464 & 0.425 \\
    \hline
europarl stacking, en only +syntactic & 0.486 & 0.527 & 0.472 & 0.436 \\
    \hline
europarl stacking, 5 languages & 0.483 & 0.523 & 0.466 & 0.428 \\
    \hline
europarl stacking, 5 languages +syntactic & \emph{0.487} & 0.527 & \emph{0.473} & 0.438 \\
    \hline
  \end{tabulary}
  \end{centering}
  \caption{Results for stacking with Europarl.}
  \label{fig:europarl-stacking-results}
\end{figure*}

\subsection{Results: classifier stacking with Bibles}

In Figure \ref{fig:bible-stacking-results}, we see our results for the
experiments with stacking using Bibles as bitext.


\begin{figure*}
  \begin{centering}
  \begin{tabulary}{\textwidth}{|R|L|L|L|L|}
    \hline
    classifier & es-gn regular & es-gn non-null & es-qu regular & es-qu non-null \\

    \hline
    MFS    & 0.456 & 0.498 & 0.435 & 0.391 \\
    \hline
    \hline

    \multicolumn{5}{|l|}{maxent l1} \\
    \hline
    baseline features & 0.461 & 0.506 & 0.444 & 0.414 \\
    \hline
    +all syntactic features & 0.465 & 0.511 & 0.450 & 0.422 \\
    \hline
bible stacking, en only & 0.463 & 0.508 & 0.446 & 0.416 \\
    \hline
bible stacking, en only +syntactic & 0.466 & 0.513 & 0.451 & 0.425 \\
    \hline
bible stacking, 5 languages & 0.466 & 0.512 & 0.449 & 0.419 \\
    \hline
bible stacking, 5 languages +syntactic & 0.469 & 0.516 & 0.453 & 0.427 \\
    \hline
    \hline

    \multicolumn{5}{|l|}{maxent l2} \\
    \hline
    baseline features & 0.475 & 0.524 & 0.458 & 0.431 \\
    \hline
    +all syntactic features & 0.480 & 0.530 & 0.465 & 0.441 \\
    \hline
bible stacking, en only & 0.478 & 0.527 & 0.461 & 0.435 \\
    \hline
bible stacking, en only +syntactic & 0.482 & 0.532 & 0.467 & 0.444 \\
    \hline
bible stacking, 5 languages & 0.484 & 0.533 & 0.468 & 0.443 \\
    \hline
bible stacking, 5 languages +syntactic & 0.487 & \textbf{0.538} & 0.472 & \textbf{0.450} \\
    \hline

    \multicolumn{5}{|l|}{random forest} \\
    \hline
    baseline features & 0.481 & 0.520 & 0.464 & 0.424 \\
    \hline
    +all syntactic features & 0.486 & 0.527 & 0.471 & 0.434 \\
    \hline
bible stacking, en only & 0.484 & 0.525 & 0.466 & 0.428 \\
    \hline
bible stacking, en only +syntactic & 0.488 & 0.529 & 0.473 & 0.439 \\
    \hline
bible stacking, 5 languages & 0.488 & 0.530 & 0.470 & 0.434 \\
    \hline
bible stacking, 5 languages +syntactic & \textbf{0.492} & 0.533 & \textbf{0.476} & 0.441 \\
    \hline
  \end{tabulary}
  \end{centering}
  \caption{Results for stacking with Bibles.}
  \label{fig:bible-stacking-results}
\end{figure*}

\subsection{Results: classifier stacking with both Europarl and Bibles}

Finally, in Figure \ref{fig:both-stacking-results}, we show the results for
experiments where we used stacking features from both Bibles and the Europarl
corpus. The results in general were quite similar those we saw with using Bible
stacking features alone; the addition of the features from classifiers trained
on Europarl did not help.

\begin{figure*}
  \begin{centering}
  \begin{tabulary}{\textwidth}{|R|L|L|L|L|}
    \hline
    classifier & es-gn regular & es-gn non-null & es-qu regular & es-qu non-null \\

    \hline
    MFS    & 0.456 & 0.498 & 0.435 & 0.391 \\
    \hline
    \hline

    \multicolumn{5}{|l|}{maxent l1} \\
    \hline
    baseline features & 0.461 & 0.506 & 0.444 & 0.414 \\
    \hline
    +all syntactic features & 0.465 & 0.511 & 0.450 & 0.422 \\
    \hline
both stacking, 5 languages & 0.465 & 0.511 & 0.448 & 0.419 \\
    \hline
both stacking, 5 languages +syntactic & 0.468 & 0.516 & 0.452 & 0.426 \\
    \hline
    \hline

    \multicolumn{5}{|l|}{maxent l2} \\
    \hline
    baseline features & 0.475 & 0.524 & 0.458 & 0.431 \\
    \hline
    +all syntactic features & 0.480 & 0.530 & 0.465 & 0.441 \\
    \hline
both stacking, 5 languages & 0.484 & 0.533 & 0.469 & 0.444 \\
    \hline
both stacking, 5 languages +syntactic & 0.487 & \textbf{0.538} & 0.473 & \textbf{0.450} \\
    \hline
    \hline

    \multicolumn{5}{|l|}{random forest} \\
    \hline
    baseline features & 0.481 & 0.520 & 0.464 & 0.424 \\
    \hline
    +all syntactic features & 0.486 & 0.527 & 0.471 & 0.434 \\
    \hline
both stacking, 5 languages & 0.489 & 0.530 & 0.471 & 0.434 \\
    \hline
both stacking, 5 languages +syntactic & \textbf{0.492} & 0.533 & \emph{0.475} & 0.443 \\
    \hline
    \hline

  \end{tabulary}
  \end{centering}
  \caption{Results for stacking with Bibles.}
  \label{fig:both-stacking-results}
\end{figure*}

\section{Discussion}
In this chapter we have described a straightforward approach for making use of
supplemental bitext corpora that pair our resource-rich source language with
languages other than our under-resourced target languages, adding annotations
to our bitext corpus based on the predictions of CL-WSD classifiers trained on
these supplemental bitext corpora.

We see a small but consistent performance gains from this approach when we
train on corpora of a different domain (the Europarl corpora), and a larger
gain when we train on corpora that match the domain of our bitext for the
under-resourced languages (our multilingual Bibles). The gain from using the
supplemental corpora with a close domain match was roughly as large as that
from adding syntactic annotations, described in the previous chapter.
Happily, we find that multilingual evidence and syntactic annotations can be
used together effectively; we can train the highest-performing CL-WSD
classifiers in this work so far by adding both sets of features.

In the next chapter, we will switch our focus to practical applications of
CL-WSD and the Chipa software, showing how it can be integrated into a sampling
of MT systems of different architectures, improving MT performance in practice.
