\chapter{Learning from Multilingual Data}
\label{chap:multilingual}

As discussed in previous chapters, while our target languages are
under-resourced, we have many resources available for our source languages.
Concretely for Spanish, in addition to the abundant monolingual text and
off-the-shelf NLP tools, as discussed in Chapter \ref{chap:monolingual}, we
have a significant amount of bitext, pairing Spanish with languages other than
our under-resourced target languages. We would like to be able to learn from
these other bitext corpora when translating from Spanish to Guarani and
Quechua, and ideally in general from resource-rich source languages into
under-resourced target languages.

Each bitext corpus may contain useful examples of a given source language word,
and senses of that word may be lexicalized differently in the various target
languages, giving us clues about the meaning of each token in its context.
Selecting a contextually correct translation for source-language words is
evidence that we have understood the meaning of those words, at least
implicitly, in as far as sense distinctions are surfaced in the target
language. So we would like our system to be able to learn relationships between
the senses of a given source word, as they are represented in different target
languages. Two target languages may happen to surface similar sense
distinctions, perhaps due to being related languages, or perhaps because a word
sense ambiguity is unusual in the source language, or simply by coincidence.
Additionally, a combination of translations into several languages may provide
evidence for a certain lexical choice in the target language of interest.

In this chapter, we present strategies for learning from the available bitext
corpora that do not include our under-resourced target languages, to help us
make better CL-WSD decisions when translating into them. Primarily we discuss a
``classifier stacking" approach, in which we train CL-WSD classifiers
translating from Spanish to other European languages, and use the outputs of
these classifiers as features for Spanish to Quechua and Spanish to Guarani.

The approaches in this chapter are particularly informed by the work of Els
Lefever \emph{et. al} (see especially
\cite{lefever-hoste-decock:2011:ACL-HLT2011}), in which entire source sentences
are machine-translated into several different target languages just before
feature extraction, and these entire sentences are used to produce signals for
CL-WSD classifiers. One drawback of this technique is that it could be
considered unwieldy from a software engineering perspective; it requires
multiple complete MT systems to perform CL-WSD, which is rather complex when we
want to use CL-WSD as a subcomponent of a machine translation system in the
first place.

In earlier work, considering the work of Lefever \emph{et. al}, we developed
some prototype CL-WSD systems that made use of multilingual evidence
\cite{rudnick-liu-gasser:2013:SemEval-2013} and produced some of the top
results in a SemEval shared task on CL-WSD \cite{task10}.
Here our systems trained with multilingual evidence posted better performance
than the one that used monolingual features; our top results in every language
came from either classifier stacking or the Markov network classifier. This
suggests that it is possible to use evidence in several parallel corpora for
CL-WSD without translating source sentences into many target languages.

In this SemEval paper, we presented two different approaches for making use of
multilingual evidence. The more complex of them was a system based on graphical
models that performed loopy belief propagation over Markov networks, which we
will discuss briefly in Section~\ref{sec:multilingual-mrf}. The simpler
approach described in that work was a relatively straightforward classifier
stacking approach, where the outputs of several CL-WSD classifiers were used as
input features for one final classifier. This approach is more immediately
applicable to lexical selection when our target language is under-resourced, as
it does not require bitext corpora between all of the involved languages.

\section{Multilingual evidence from the Europarl corpus} 
There are quite a few bitext resources available for many European languages,
especially the official languages of the European Union.
Through the Europarl corpus \cite{europarl}, for example, we have bitext
corpora in which Spanish is paired with English, German, French, and 17 other
European languages.

%% XXX what else to say about Europarl?

\section{Multilingual evidence from Bible translations}
%% XXX we're also going to have to write about training on the bibles here.

\section{CL-WSD with Markov Networks}
\label{sec:multilingual-mrf}
In our SemEval entry \cite{rudnick-liu-gasser:2013:SemEval-2013}, we
investigated a CL-WSD approach based on Markov networks (also known as ``Markov
Random Fields"), building a network of interacting variables (see Figure
\ref{fig:pentagram}) to solve CL-WSD classification problems for the five
target languages of the SemEval 2013 task \cite{task10}. In this task, we were
given English source sentences with an annotated focus word (from a given set
of possible focus words types), and asked to make correct lexical selections
for translating into Dutch, French, German, Italian and Spanish. The ground
truth for the task was determined by human annotators familiar with those
languages.

Here the nodes in our Markov network represent random variables that take on
values corresponding to the possible translations for each of the five target
languages. The probability distributions over these translations are produced
by language-specific maximum entropy classifiers, effectively applying the
baseline Chipa system on the given input sentence.

The edges in the graph correspond to pairwise potentials that are derived from
the joint probabilities of target language labels co-occurring in the available
bitext for the two target languages along that edge of the graph. This approach
thus requires a bitext corpus for each pair of languages in the set of
languages involved; for the SemEval task, we worked with a subset of the
Europarl corpus, provided by the task organizers, in which every sentence was
provided for all six languages.

We frame the task of finding the optimal translations into five languages
jointly as a MAP inference problem, wherein we try to maximize the joint
probability of all five variables, given the single source language sentence.
We perform inference with loopy belief propagation
\cite{DBLP:conf/uai/MurphyWJ99}, which is an approximate but tractable
inference algorithm that, while giving no guarantees, often produces good
solutions in practice.
We used the formulation for pairwise Markov networks that passes messages
directly between the nodes rather than first constructing a ``cluster graph",
which is described in \cite[\S 11.3.5.1]{Koller+Friedman:09} of Koller and
Friedman's book on graphical models. This Markov network approach has the
theoretically satisfying property that it takes seriously the uncertainty
present in the predictions of each of the component classifiers and solves the
entire problem jointly. 

Intuitively, at each time step loopy belief propagation passes messages around
the graph that inform each neighbor about the estimate, from the perspective of
the sender and what it has heard from its other neighbors, of the minimum
penalty that would be incurred if the recipient node were to take a given
label. As a concrete example, when the \emph{nl} node sends a message to the
\emph{fr} node at time step 10, this message is a table mapping from all
possible French translations of the current target word to their associated
penalty values. The message depends on three things: the probability
distribution from a monolingual classifier just for Dutch, joint probabilities
estimated from our Dutch-French bitext, and the messages from the \emph{es},
\emph{it} and \emph{de} nodes from time step 9.

\begin{figure}
  \begin{center}
  \includegraphics[width=5cm]{pentagram.pdf}
  \end{center}
  \caption{The network structure used in the MRF system for SemEval: a complete
  graph with five nodes, in which each node represents the random variable for
  the translation into a target language.}
  \label{fig:pentagram}
\end{figure}

%% XXX: this needs a better explanation; we can't help the gn classifier with
%% the MRF in this graph.
\begin{figure}
  \begin{center}
  \includegraphics[width=5cm]{gn-qu-mrf.pdf}
  \end{center}
  \caption{Hypothetical network structure -- not fully connected -- that could
  be used for a Markov network, if we had a bitext corpus for Spanish and every
  other language, for German-English, and for German-Quechua. Here we draw a
  shaded node for Spanish, representing the bitext between the source language
  and each of the }
  \label{fig:gn-qu-mrf}
\end{figure}

While we were able to achieve fairly good results with these MRF-based
classifiers on the Semeval CL-WSD task, our strategy for setting the weights in
the Markov network requires, for each edge in the graph, a parallel corpus for
the corresponding language pair. The bitext for each language pair need not be
mutually parallel among all of the languages present; each edge in the graph
may correspond to an unrelated bitext corpus.  Also, in principle the graph
need not be fully connected, as it was for our SemEval entry, but this approach
does require bitext between the source language, our target language of
interest, and at least one of the other language; see
Figure~\ref{fig:gn-qu-mrf} for a hypothetical network structure that could be
used, given the right bitext.

Considering the limited bitext resources available, this approach is less
easily applicable for the under-resourced target language use case.  In the
classifier stacking approach, it is clear how we can include information from
many heterogeneous sources. The Markov network approach may be useful for
future CL-WSD systems in other settings, but we will not make further use of it
for translating into under-resourced languages, since we do not have many
parallel corpora available for Guarani or Quechua.

\section{Classifier stacking}
The classifier stacking approach, in order to predict the translation of a word
into a given target language, uses translations into \emph{other} available
target languages as features.
For example, for our SemEval prototype systems, in order to translate an
English word into Spanish, we predict that word's translations into French,
Italian, Dutch and German, and then encode those predicted translations as
features for our English to Spanish classifier.

This approach only requires that the classifiers make \emph{some} prediction
based on text in the source language; they need not be trained from the same
source text, depend on the same features, or even output words as labels.
%% XXX: ... wait, what?

\subsection{Classifier stacking in practice}
Here we train the baseline Chipa system, with the baseline feature set, on both
Europarl bitext pairing Spanish with five other languages, and on verse-aligned
Bible translations, for the same five European target languages. Following
earlier work, including our system for SemEval and that of Lefever \emph{et
al.}, the target languages used are Dutch, English, French, German, and
Italian.

The bitext corpora are prepared with the tools distributed with the Europarl
corpus, which conveniently produce sentence-aligned and tokenized bitext.  We
then preprocess the bitext with the same steps we used on our Bible text, as
described in Section~\label{sec:datasetsandpreprocessing}. Where possible, we
lemmatize the target-language text with FreeLing.  However, as of this writing
FreeLing does not support Dutch, so for Dutch, we use the Frog text analysis
tool\footnote{Frog was developed by groups at Tilburg University and the
University of Antwerp. It is available at
\url{http://languagemachines.github.io/frog/}} \cite{tadpole2007}. With the
exception of the different lemmatizer for Dutch, the preprocessing steps are
analogous to those described in the previous chapters, resulting in
automatically aligned Spanish-Dutch, Spanish-English, Spanish-French,
Spanish-German, and Spanish-Italian bitext corpora.

%% XXX maybe move all this text into the sections about the individual corpora?
%% XXX probably talk about how many sentence pairs we end up with?

\section{Domain mismatches}

In comparing the use of different corpora for our classifier stacking approach,
we want to ask to what extent the domain mismatch will play a role.
The subjets discussed in European Parliament may not match that of our
Spanish-Guarani and Spanish-Quechua corpora; furthermore, perhaps the Spanish
words used may not match at all.

Exploring the corpora a bit, we find that, indeed, many of the word types used
in our Spanish Bible translation either never appear, or only appear very
rarely in the Europarl text.

\section{Experiments}
\label{sec:multilingual-experiments}

The experiments in this chapter are analogous to the ones in previous chapters,
with the addition of features based on classifier stacking. Following the work
of Lefever \emph{et al.} and our earlier SemEval entry, we trained
classifiers mapping from Spanish to Dutch, English, French German and Italian,
based on both the Europarl corpus and our available Bible translations. When
annotating the bitext for Spanish-Guarani, we trained classifiers for each of
the in-vocabulary focus words for that language pair (see Section
\ref{sec:exploring}), and likewise for Spanish-Quechua.

All classifiers were trained with the baseline features described in
Chapter~\ref{chap:baseline}, and some were trained with the syntactic features
described in Chapter~\ref{chap:monolingual}. The new features introduced in
this chapter are presented in Figure~\ref{fig:stackingfeatures}.

\begin{figure*}
  \begin{centering}
  \begin{tabular}{|p{3.5cm}|p{11cm}|}
    \hline
    name          & description  \\
    \hline
    \texttt{stacking\_en} & Predicted translation of the current token into
    English, if one was available. Feature is not present if no prediction was
    made for this token. \\
    \hline
    \texttt{stacking\_de}, \texttt{stacking\_fr}, \texttt{stacking\_it},
    \texttt{stacking\_nl} & \emph{ibid.}, but with a prediction into the
    corresponding language.\\
    \hline
    \texttt{stacking\_window} & The predictions for any tokens in the
    surrounding context window, into any of the available languages for this
    run. \\
    \hline
  \end{tabular}
  \end{centering}
  \caption{Classifier features based on classifier stacking, used in these
  experiments}
  \label{fig:stackingfeatures}
\end{figure*}

\section{Experimental Results}
\label{sec:multilingual-results}

This section contains many tables of numbers; in general, for each set of
experimental results presented, the top result for each setting is presented in
\emph{italics}, and the top result for a setting presented in the whole chapter
is presented in \textbf{bold}.

\subsection{Results: classifier stacking with Europarl}

In Figure \ref{fig:europarl-stacking-results}, we present results for the
experiments with stacking using the Europarl bitext.

\begin{figure*}
  \begin{centering}
  \begin{tabulary}{\textwidth}{|R|L|L|L|L|}
    \hline
    classifier & es-gn regular & es-gn non-null & es-qu regular & es-qu non-null \\

    \hline
    MFS    & 0.456 & 0.498 & 0.435 & 0.391 \\
    \hline
    \hline

    \multicolumn{5}{|l|}{maxent l1} \\
    \hline
    baseline features & 0.461 & 0.506 & 0.444 & 0.414 \\
    \hline
    +all syntactic features & 0.465 & 0.511 & 0.450 & 0.422 \\
    \hline
europarl stacking, en only & 0.461 & 0.506 & 0.444 & 0.414 \\
    \hline
europarl stacking, en only +syntactic & 0.465 & 0.511 & 0.450 & 0.422 \\
    \hline
europarl stacking, 5 languages & 0.460 & 0.505 & 0.444 & 0.414 \\
    \hline
europarl stacking, 5 languages +syntactic & 0.464 & 0.510 & 0.449 & 0.422 \\
    \hline
    \hline

    \multicolumn{5}{|l|}{maxent l2} \\
    \hline
    baseline features & 0.475 & 0.524 & 0.458 & 0.431 \\
    \hline
    +all syntactic features & 0.480 & 0.530 & 0.465 & 0.441 \\
    \hline
europarl stacking, en only & 0.476 & 0.525 & 0.458 & 0.433 \\
    \hline
europarl stacking, en only +syntactic & 0.481 & 0.530 & 0.466 & 0.442 \\
    \hline
europarl stacking, 5 languages & 0.477 & 0.526 & 0.461 & 0.435 \\
    \hline
europarl stacking, 5 languages +syntactic & 0.482 & \emph{0.531} & 0.467 & \emph{0.444} \\
    \hline
    \hline

    \multicolumn{5}{|l|}{random forest} \\
    \hline
    baseline features & 0.481 & 0.520 & 0.464 & 0.424 \\
    \hline
    +all syntactic features & 0.486 & 0.527 & 0.471 & 0.434 \\
    \hline
europarl stacking, en only & 0.482 & 0.522 & 0.464 & 0.425 \\
    \hline
europarl stacking, en only +syntactic & 0.486 & 0.527 & 0.472 & 0.436 \\
    \hline
europarl stacking, 5 languages & 0.483 & 0.523 & 0.466 & 0.428 \\
    \hline
europarl stacking, 5 languages +syntactic & \emph{0.487} & 0.527 & \emph{0.473} & 0.438 \\
    \hline
  \end{tabulary}
  \end{centering}
  \caption{Results for stacking with Europarl.}
  \label{fig:europarl-stacking-results}
\end{figure*}

\subsection{Results: classifier stacking with Bibles}

In Figure \ref{fig:bible-stacking-results}, we see our results for the
experiments with stacking using Bibles as bitext.


\begin{figure*}
  \begin{centering}
  \begin{tabulary}{\textwidth}{|R|L|L|L|L|}
    \hline
    classifier & es-gn regular & es-gn non-null & es-qu regular & es-qu non-null \\

    \hline
    MFS    & 0.456 & 0.498 & 0.435 & 0.391 \\
    \hline
    \hline

    \multicolumn{5}{|l|}{maxent l1} \\
    \hline
    baseline features & 0.461 & 0.506 & 0.444 & 0.414 \\
    \hline
    +all syntactic features & 0.465 & 0.511 & 0.450 & 0.422 \\
    \hline
bible stacking, en only & 0.463 & 0.508 & 0.446 & 0.416 \\
    \hline
bible stacking, en only +syntactic & 0.466 & 0.513 & 0.451 & 0.425 \\
    \hline
bible stacking, 5 languages & 0.466 & 0.512 & 0.449 & 0.419 \\
    \hline
bible stacking, 5 languages +syntactic & 0.469 & 0.516 & 0.453 & 0.427 \\
    \hline
    \hline

    \multicolumn{5}{|l|}{maxent l2} \\
    \hline
    baseline features & 0.475 & 0.524 & 0.458 & 0.431 \\
    \hline
    +all syntactic features & 0.480 & 0.530 & 0.465 & 0.441 \\
    \hline
bible stacking, en only & 0.478 & 0.527 & 0.461 & 0.435 \\
    \hline
bible stacking, en only +syntactic & 0.482 & 0.532 & 0.467 & 0.444 \\
    \hline
bible stacking, 5 languages & 0.484 & 0.533 & 0.468 & 0.443 \\
    \hline
bible stacking, 5 languages +syntactic & 0.487 & \textbf{0.538} & 0.472 & \textbf{0.450} \\
    \hline

    \multicolumn{5}{|l|}{random forest} \\
    \hline
    baseline features & 0.481 & 0.520 & 0.464 & 0.424 \\
    \hline
    +all syntactic features & 0.486 & 0.527 & 0.471 & 0.434 \\
    \hline
bible stacking, en only & 0.484 & 0.525 & 0.466 & 0.428 \\
    \hline
bible stacking, en only +syntactic & 0.488 & 0.529 & 0.473 & 0.439 \\
    \hline
bible stacking, 5 languages & 0.488 & 0.530 & 0.470 & 0.434 \\
    \hline
bible stacking, 5 languages +syntactic & \textbf{0.492} & 0.533 & \textbf{0.476} & 0.441 \\
    \hline
  \end{tabulary}
  \end{centering}
  \caption{Results for stacking with Bibles.}
  \label{fig:bible-stacking-results}
\end{figure*}

\subsection{Results: classifier stacking with both Europarl and Bibles}

Finally, in Figure \ref{fig:both-stacking-results}, we show the results for
experiments where we used stacking features from both Bibles and the Europarl
corpus. The results in general were quite similar those we saw with using Bible
stacking features alone; the addition of the features from classifiers trained
on Europarl did not help.

\begin{figure*}
  \begin{centering}
  \begin{tabulary}{\textwidth}{|R|L|L|L|L|}
    \hline
    classifier & es-gn regular & es-gn non-null & es-qu regular & es-qu non-null \\

    \hline
    MFS    & 0.456 & 0.498 & 0.435 & 0.391 \\
    \hline
    \hline

    \multicolumn{5}{|l|}{maxent l1} \\
    \hline
    baseline features & 0.461 & 0.506 & 0.444 & 0.414 \\
    \hline
    +all syntactic features & 0.465 & 0.511 & 0.450 & 0.422 \\
    \hline
both stacking, 5 languages & 0.465 & 0.511 & 0.448 & 0.419 \\
    \hline
both stacking, 5 languages +syntactic & 0.468 & 0.516 & 0.452 & 0.426 \\
    \hline
    \hline

    \multicolumn{5}{|l|}{maxent l2} \\
    \hline
    baseline features & 0.475 & 0.524 & 0.458 & 0.431 \\
    \hline
    +all syntactic features & 0.480 & 0.530 & 0.465 & 0.441 \\
    \hline
both stacking, 5 languages & 0.484 & 0.533 & 0.469 & 0.444 \\
    \hline
both stacking, 5 languages +syntactic & 0.487 & \textbf{0.538} & 0.473 & \textbf{0.450} \\
    \hline
    \hline

    \multicolumn{5}{|l|}{random forest} \\
    \hline
    baseline features & 0.481 & 0.520 & 0.464 & 0.424 \\
    \hline
    +all syntactic features & 0.486 & 0.527 & 0.471 & 0.434 \\
    \hline
both stacking, 5 languages & 0.489 & 0.530 & 0.471 & 0.434 \\
    \hline
both stacking, 5 languages +syntactic & \textbf{0.492} & 0.533 & \emph{0.475} & 0.443 \\
    \hline
    \hline

  \end{tabulary}
  \end{centering}
  \caption{Results for stacking with Bibles.}
  \label{fig:both-stacking-results}
\end{figure*}

\section{Discussion}

