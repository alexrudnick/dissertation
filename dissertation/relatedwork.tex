\chapter{Related Work}
\label{chap:relatedwork}

In this chapter, I will review some of the recent related work, including
techniques for CL-WSD considered as a task on its own, the application of
classifiers to lexical selection in various machine translation architectures,
techniques used in recent runnings of the SemEval task on CL-WSD, and some
relevant approaches for word-sense disambiguation more broadly. The Chipa
software and the work described in the rest of the dissertation draws heavily
from ideas described here; how particular ideas have been influential will be
highlighted as we get to them.

%% XXX consider: is this the best structure, even?

\section{CL-WSD \emph{in vitro}}
Some of the previous work on CL-WSD has studied the CL-WSD task in isolation, 
without being embedded into a machine translation system as such.
It is sensible to explore CL-WSD on its own for several reasons. Firstly, even
if our motivation for developing CL-WSD is to improve machine translation
output, from an engineering perspective, we still want to get a sense of
how well the individual components of our pipeline are functioning.
Furthermore, if the MT pipeline is relying on a CL-WSD system to help it with
lexical selection, one expects that improved disambiguation accuracy will
result in better translations overall -- though of course in complex software,
unexpected interactions may occur.


\subsection{Multilingual Evidence for CL-WSD}
One of the most interesting CL-WSD systems of recent years, which inspired our
use of multilingual evidence in Chipa, is ParaSense
\cite{lefever-hoste-decock:2011:ACL-HLT2011}, developed by Els Lefever and
colleagues.

ParaSense uses memory-based learning to predict target-language translations of
individual source-language words in a lexical sample task. It starts with
features that one would expect for a text classification problem: the surface
forms, POS tags, and lemmas for the focus word and the tokens in a small window
around it, as well as some syntactic information from a chunk parser. But
ParaSense also includes bag-of-words features for translations of the input
sentence into languages \emph{other} than the target language. ParaSense
handles translation from English into French, Spanish, Italian, Dutch and
German, so for example when translating from English to French, it includes
bag-of-words features extracted from the translations of the English sentence
into Spanish, Italian, Dutch and German (but not French).

Given corpora that are parallel over many languages, such as Europarl, this is
straightforward at training time. However, at testing time it is faced with a
novel sentence for which it has no translation. Here ParaSense requires a
complete MT system for each of the four other languages: it generates a
translation into the other four languages.
When ParaSense was being developed, it simply called out to the Google
Translate API (which is, as of this writing, no longer available gratis) to
generate the bag-of-words features required for test sentences.
This seems unwieldy and arguably detrimental to reproducible research: it
benefits from whatever techniques Google Translate uses for word choice,
which are not necessarily discussed with the public, and will change
without warning over time.

Critiques aside, ParaSense is very effective for its task.  When applied to the
SemEval 2010 CL-WSD task test data (described in
\cite{lefever-hoste:2010:SemEval}), it outperformed all of the systems
submitted for that task for nearly all of the target languages, being
outperformed, by a small margin, for one system when targeting Spanish
\cite{lefever-hoste-decock:2011:ACL-HLT2011}.

In our earlier work, we prototyped a system that addresses some of the issues
with ParaSense \cite{rudnick-liu-gasser:2013:SemEval-2013}; these ideas are
developed further in Chapter \ref{chap:multilingual}.
Chipa requires neither a locally running MT system nor access to an online
translation API for its feature extraction, but still learns from several
mutually parallel bitexts that share a source language.


\section{WSD with Sequence Models}
To our knowledge, there has not been other work on framing CL-WSD for all words
in an input sentence as a sequence labeling problem.

%% XXX
In some sense, isn't an MT system with a LM just a richer model for
this, with different possible segmentations and reordering?

However, in monolingual WSD, Molina et al.
\cite{DBLP:conf/iberamia/MolinaPS02} have made use of HMMs for WSD. Surely
there's been more of this?

Look into the recent stuff from BabelNet and Babelfy: what are they doing
there? Could that be described as sequence models?

This section is really spotty and it'd be shocking if nobody else has tried
this at all.

\section{CL-WSD for Lexical Selection in RBMT}
Francis Tyers, in his dissertation work \cite{tyers-dissertation}, develops a
practical approach for improving lexical selection for the Apertium RBMT
system. As he described in \cite{tyers-fst}, his software learns finite-state
transducers for lexical selection from the available parallel corpora.
It is intended to be both very fast, for use in practical translation systems,
and to produce lexical selection rules that are understandable and modifiable
by humans. He also describes experiments in which humans wrote lexical
selection rules with the same framework.
The rules available to the system can make reference to the lexical items and
parts of speech surrounding the word to be translated.

%% XXX
There's more to say about this.


\section{CL-WSD for PB-SMT}

%% Brown et al
Framing the resolution of lexical ambiguities in machine translation
as an explicit classification
task has a long history, dating back at least to early SMT work at IBM
\cite{Brown91word-sensedisambiguation}.

An early paper by IBM researchers \cite{Brown91word-sensedisambiguation},
outlines the CLWSD task in a strikingly similar way, as a WSD task where the
possible senses of a word are extracted from statistical alignments learned
over a bitext corpus.
Brown et al. report significant translation quality improvements
through the use of their WSD system, over a small hand-evaluated set of test
sentences.



%% XXX

%% everything about Carpuat and Wu goes here
More recently, Carpuat and Wu have
shown how to use classifiers to improve modern phrase-based SMT systems
\cite{carpuatpsd}.
More recently, Carpuat and Wu have
shown how to use word-sense disambiguation techniques to improve modern
phrase-based SMT systems \cite{carpuatpsd}, even though the language model and
phrase tables of these systems can mitigate the problem of lexical ambiguities
somewhat.

While most SMT systems do not make use of an explicit WSD module, recently
there has been work on adding WSD classifiers in to statistical MT systems.
Particularly, Carpuat and Wu have shown how to use CL-WSD, or more broadly,
cross-lingual phrase sense disambiguation, to improve modern phrase-based SMT
systems
\cite{carpuatpsd,carpuat-wu:2007:EMNLP-CoNLL2007,carpuat2008evaluation}. In
Carpuat's work, classifiers are used to label multi-word expressions (phrases,
in the phrase-based SMT sense) with target language phrases. She demonstrates
how this is more appropriate in an an SMT setting than simply labeling
individual words with WordNet synsets, as had previously been attempted, and
showed significant improvements on a Chinese-English translation task.

While most SMT systems do not make use of an explicit WSD module, recently
there has been work on adding WSD classifiers in to statistical MT systems.
Particularly, Carpuat and Wu have shown how to use CL-WSD, or more broadly,
cross-lingual phrase sense disambiguation, to improve modern phrase-based SMT
systems
\cite{carpuatpsd,carpuat-wu:2007:EMNLP-CoNLL2007,carpuat2008evaluation}. In
Carpuat's work, classifiers are used to label multi-word expressions (phrases,
in the phrase-based SMT sense) with target language phrases. She demonstrates
how this is more appropriate in an an SMT setting than simply labeling
individual words with WordNet synsets, as had previously been attempted, and
showed significant improvements on a Chinese-English translation task.

Before the work of Carpuat and Wu~\cite{improvingsmtwsd}, it was
unclear whether a dedicated WSD module would be helpful for a state-of-the-art 
SMT system.

lexical choice among possible translations for a given word can
often be handled by the language model for the target language, simply due to
collocations of appropriate words in the training data.


There has also been work on using discriminative MaxEnt models to adapt
the ``forward" translation model of an SMT system, using richer
source-language context features \cite{vzabokrtsky-popel-marevcek:2010:WMT}.
While it has much the same effect, this work does not describe itself in terms
of word sense disambiguation.




\section{WSD for lower-resourced languages}
However, there has been work recently on using WSD techniques for translation
into lower-resourced languages, such as the English-Slovene language pair, as
in \cite{vintar-fivser-vrvsvcaj:2012:ESIRMT-HyTra2012}. 

Dinu and KÃ¼bler~\cite{Dinu07} have addressed the problem of monolingual WSD for
a lower-resourced language, particularly Romanian. In their work, they describe
an instance-based approach in which a relatively small number of features is
used quite effectively. In other work on lower-resourced languages,
Sarrafzdadeh et al. have investigated a version of the Lesk algorithm
for Farsi \cite{sarrafzdadeh}.

Although they did not present a complete MT system, there has also been work
on using WSD techniques for translation into lower-resourced languages, such as
the English-Slovene language pair, as in
the work of \v{S}pela et al.
\cite{vintar-fivser-vrvsvcaj:2012:ESIRMT-HyTra2012}. 

%% XXX
One sort of interesting point here is that we are not doing WSD on a
low-resourced language. This is ultimately WSD on Spanish with a sense
inventory that we automatically discover from cross-lingual evidence.


\section{CL-WSD at SemEval}
%% XXX
CL-WSD has received enough attention to warrant shared tasks at recent SemEval
workshops; the most recent running of the task is described by Lefever and
Hoste \cite{task10}.

Similar was the earlier task: \cite{lefever-hoste:2009:SEW}

There was also the Writing Assistant task (XXX cite Maarten), which is related
but not quite the same.

In the two CL-WSD tasks, participants were asked to translate twenty different
polysemous English nouns into five different European languages, in a variety
of contexts.

Some of the approaches explored included...


\section{Translation into Morphologically Rich Languages}
%% XXX
In Section \ref{sec:terere}, we are attempting to build a complete MT system
for the Spanish-Guarani language pair. As Guarani has a very rich morphology,
which we will need to predict and synthesize. As such, here we will quickly
review some of the work on morphological prediction and generation for
statistical MT systems.

Chris Dyer's recent paper at EMNLP
\cite{chahuneau:2013:emnlp}

Talk about prediction for morphology.
\cite{toutanova-suzuki-ruopp:2008:ACLMain}

Also factored models...
\cite{yeniterzi-oflazer:2010:ACL}
